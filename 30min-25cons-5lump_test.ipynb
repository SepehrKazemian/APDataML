{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import Plot as plot\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as offline\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "import os\n",
    "import scipy.spatial\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import matplotlib as plt\n",
    "import logging\n",
    "from scipy import signal\n",
    "import learningAlgs as classImportLA\n",
    "import dataManipulation as dataMan\n",
    "from itertools import permutations\n",
    "import importlib\n",
    "from datetime import timedelta\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.cluster import KMeans\n",
    "import timeIntervalPlotter as intervalPlotter\n",
    "import pysal\n",
    "import warnings\n",
    "import lumping_traditional as oldLumping\n",
    "import boundaryFull_SS_WeightedLumping as WLumping\n",
    "from importlib import reload\n",
    "from scipy.stats import rayleigh\n",
    "import dataManipulation as dataMan\n",
    "import matplotlib.pyplot as plt\n",
    "import processData as processData\n",
    "import tensorflow as tf\n",
    "# import tensorflow_probability as tfp\n",
    "import random\n",
    "from random import shuffle\n",
    "\n",
    "warnings.filterwarnings('always')\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pkg_resources\n",
    "pkg_resources.get_distribution(\"tensorflow\").version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Feature Engineered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"30min_featureEngineer.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifying(CU, boundaries):\n",
    "    occupiedBandwidth = (CU / 255) * 100\n",
    "    for i in range(len(boundaries)):\n",
    "        if occupiedBandwidth <= boundaries[i]:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPreparation(data, timeIndexes, minuteSplit, boundaries):\n",
    "    from sklearn.utils import shuffle\n",
    "    warnings.filterwarnings('always')\n",
    "    reg = \"l2\"\n",
    "    solvers = \"lbfgs\"\n",
    "    clf = LogisticRegression(penalty = reg, max_iter = 100000, random_state = 0,\n",
    "                             solver = solvers , multi_class = 'multinomial')\n",
    "    accuracyValue = 0\n",
    "    numOfElements = 0\n",
    "    f1scoreValue = 0\n",
    "    precisionValue = 0\n",
    "    recallValue = 0\n",
    "    prevRowTrain = np.inf\n",
    "    prevCU = np.inf\n",
    "\n",
    "    sampleIntervals = 6 #seconds\n",
    "    minuteSplit = 30 #minutes\n",
    "    numOfSamples = minuteSplit * 60 / sampleIntervals\n",
    "    # numberOfDays = len(numOfDays)\n",
    "    days = np.zeros(7)\n",
    "    numOfThirtyMinsPerDay = np.zeros(int((24 * 60) / minuteSplit)) #in this case 48\n",
    "#     which6SecondsPerPeriod = np.zeros(int(minuteSplit * 60 / sampleIntervals)) #in this case 300\n",
    "    prevRowTrain = np.inf\n",
    "    prevCU = np.inf\n",
    "\n",
    "    XArraysForLearning = []\n",
    "    YArraysForLearning = []\n",
    "    XArraysForTesting = []\n",
    "    YArraysForTesting = []\n",
    "\n",
    "    x = timeIndexes\n",
    "    wholeDataFrame = data.loc[(data[\"timeIndex\"] == x)].copy()\n",
    "    \n",
    "    wholeDataFrame[\"cuClass\"] = wholeDataFrame[\"CU\"].apply(lambda x: classifying(x, boundaries))\n",
    "\n",
    "    \n",
    "\n",
    "    stackCounter = 0\n",
    "    prevCU = 0\n",
    "    prev2CU = 0\n",
    "    prev3CU = 0\n",
    "    prev4CU = 0\n",
    "    prev5CU = 0\n",
    "    print(\"start training set generation\")\n",
    "    #number of features are: prevCU + 48 correlations + 1 logDiff\n",
    "    numberOfFeatures = len(boundaries) + 48 + 1 \n",
    "    \n",
    "    XArraysForLearning = np.zeros(shape=(len(wholeDataFrame), numberOfFeatures))\n",
    "    YArraysForLearning = np.zeros(shape=(len(wholeDataFrame), len(boundaries)))\n",
    "#     print(len(trainingDataFrame))\n",
    "    counter = 0\n",
    "    pandasIndexCounter = 0\n",
    "    for index, row in wholeDataFrame.iterrows():\n",
    "        XArraysForLearning[pandasIndexCounter, prevCU] = 1\n",
    "        for corrs in range(48):\n",
    "            XArraysForLearning[pandasIndexCounter, len(boundaries) + corrs] = row[\"corr\" + str(corrs + 1)]\n",
    "\n",
    "        XArraysForLearning[pandasIndexCounter, len(boundaries) + 48] = row[\"normalLogDiff\"]\n",
    "        YArraysForLearning[pandasIndexCounter, row[\"cuClass\"]] = 1\n",
    "#         print(XArraysForLearning[pandasIndexCounter])\n",
    "\n",
    "        which6SecondsPerPeriod = 0\n",
    "    \n",
    "        prevCU = row[\"cuClass\"]\n",
    "        pandasIndexCounter += 1\n",
    "\n",
    "    XArraysForLearning, YArraysForLearning = shuffle(XArraysForLearning, YArraysForLearning, random_state=0)\n",
    "    XArraysForTraining = XArraysForLearning[:int(0.8*len(XArraysForLearning))]\n",
    "    YArraysForTraining = YArraysForLearning[:int(0.8*len(YArraysForLearning))]\n",
    "    XArraysForTesting = XArraysForLearning[int(0.8*len(XArraysForLearning)):]\n",
    "    YArraysForTesting = YArraysForLearning[int(0.8*len(YArraysForLearning)):]\n",
    "    print(XArraysForTraining.shape[0])\n",
    "    print(XArraysForTesting.shape[0])\n",
    "\n",
    "\n",
    "    return XArraysForTraining, YArraysForTraining, XArraysForTesting, YArraysForTesting, boundaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Function Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorFlowLossFunction(\n",
    "    lossFuncBool, XArraysForLearning, YArraysForLearning, XArraysForTesting, YArraysForTesting, boundaries):\n",
    "    \n",
    "    batch_size = 64\n",
    "    learning_rate = 0.01\n",
    "    beta = 0.1\n",
    "    numOfEpochs = 500\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        x = tf.placeholder(tf.float32, shape = (batch_size, XArraysForLearning.shape[1]))\n",
    "        y_ = tf.placeholder(tf.float32, shape = (batch_size, YArraysForLearning.shape[1]))\n",
    "#         print(weights.dtype)\n",
    "#         print(weights.shape)\n",
    "#         print(XArraysForLearning.shape[1], YArraysForLearning.shape[1])\n",
    "#         multiDistrib = np.vstack((mult, mult))\n",
    "#         for i in range(batch_size - 2):\n",
    "#             multiDistrib = np.vstack((multiDistrib, mult))\n",
    "        W = tf.Variable(tf.truncated_normal([XArraysForLearning.shape[1], YArraysForLearning.shape[1]], seed = 0), name=\"weights\", dtype=tf.float32)\n",
    "        b = tf.Variable(tf.truncated_normal([YArraysForLearning.shape[1]], seed = 0), dtype=tf.float32)\n",
    "\n",
    "        tf_test_dataset64 = tf.constant(XArraysForTesting)\n",
    "        tf_test_dataset = tf.cast(tf_test_dataset64, tf.float32)\n",
    "\n",
    "\n",
    "        beta = 0.05\n",
    "        logits = tf.matmul(x, W)\n",
    "        train_prediction = tf.nn.softmax(logits)\n",
    "        # train_prediction = tf.nn.softmax_cross_entropy_with_logits_v2(labels = y_, logits = logits)\n",
    "        test_prediction = tf.nn.softmax(tf.add(tf.matmul(tf_test_dataset, W),b))\n",
    "\n",
    "        # x = XArraysForLearning[0:(0 + batch_size), :]\n",
    "        # y_ = tf.Variable(YArraysForLearning[0:(0 + batch_size), :])\n",
    "\n",
    "        # loss = assymetricLossFunction(train_prediction, y_, boundaries)\n",
    "        # loss = assymetricLossFunction(train_prediction, y_, boundaries)\n",
    "        \n",
    "        if lossFuncBool == 0:\n",
    "            loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = y_)\n",
    "        \n",
    "        elif lossFuncBool == 1:\n",
    "            loss = assymetricLossFunction(train_prediction, y_, boundaries)\n",
    "#         dist = tfp.distributions.Multinomial(total_count=1, logits=logits)\n",
    "#         loss = loss - (dist.log_prob(mult))\n",
    "        # regularizer = tf.nn.l2_loss(W)\n",
    "        # loss = tf.reduce_mean(loss + beta * regularizer)\n",
    "        # loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits = train_prediction, labels = y_)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "        prevAcc = 0\n",
    "\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        initializer = tf.contrib.layers.xavier_initializer()\n",
    "        tf.set_random_seed(0)\n",
    "        W = tf.Variable(initializer([XArraysForLearning.shape[1], YArraysForLearning.shape[1]]))\n",
    "        b = tf.Variable(initializer([YArraysForLearning.shape[1]]))       \n",
    "        tf.global_variables_initializer().run()\n",
    "#         print(W.eval())\n",
    "        \n",
    "        print(\"Initialized\")\n",
    "\n",
    "        numberOfBatchIteration = int(XArraysForLearning.shape[0] / batch_size)\n",
    "        restOfData = XArraysForLearning.shape[0] % batch_size\n",
    "        if restOfData != 0:\n",
    "            numberOfBatchIteration += 1\n",
    "\n",
    "        accuracy_result = 0\n",
    "        accuracy_earlyStop = 0\n",
    "        earlyStoppingCounter = 0\n",
    "        \n",
    "        for epoch in range(numOfEpochs):\n",
    "            accuracyValue = 0\n",
    "            lossValue = 0\n",
    "            totalBatch = 0\n",
    "            i = 0\n",
    "            randomize = np.arange(XArraysForLearning.shape[0])\n",
    "            random.Random(epoch).shuffle(randomize)\n",
    "            XArraysForLearning = XArraysForLearning[randomize]\n",
    "            YArraysForLearning = YArraysForLearning[randomize]\n",
    "\n",
    "            for iteration in range(numberOfBatchIteration):\n",
    "                if (iteration == numberOfBatchIteration - 1) and restOfData != 0:\n",
    "                    break\n",
    "                    batch_data = XArraysForLearning[i:, :]\n",
    "                    batch_labels = YArraysForLearning[i:, :]\n",
    "\n",
    "                else:\n",
    "                    batch_data = XArraysForLearning[i:(i + batch_size), :]\n",
    "                    batch_labels = YArraysForLearning[i:(i + batch_size), :]\n",
    "\n",
    "                    i += batch_size\n",
    "\n",
    "\n",
    "                feed_dict = {x : batch_data, y_ : batch_labels}\n",
    "                _, predictions, l = session.run([optimizer, train_prediction, loss], feed_dict=feed_dict)\n",
    "\n",
    "#                 print(l)\n",
    "                lossValue *= (iteration)\n",
    "                lossValue += (np.sum(l))\n",
    "                lossValue /= (iteration + 1)\n",
    "                totalBatch += batch_size\n",
    "                # print(accuracy(batch_data, batch_labels))\n",
    "                accuracyValue += accuracy(predictions, batch_labels) * batch_size\n",
    "#                 if accuracy(test_prediction.eval(), YArraysForTesting) < prevAcc and earlyStoppingCounter == 100:\n",
    "#                     print(prevAcc)\n",
    "#                     break\n",
    "                \n",
    "#                 elif accuracy(test_prediction.eval(), YArraysForTesting) < prevAcc:\n",
    "#                     earlyStoppingCounter += 1\n",
    "                \n",
    "#                 elif accuracy(test_prediction.eval(), YArraysForTesting) >= prevAcc:\n",
    "#                     earlyStoppingCounter = 0\n",
    "\n",
    "            totalAccuracy = accuracyValue/totalBatch\n",
    "#             print(session.run(W))\n",
    "            print(\"epoch \", epoch, totalAccuracy)\n",
    "#             if accuracy(test_prediction.eval(), YArraysForTesting) > accuracy_earlyStop:\n",
    "#                 accuracy_earlyStop = accuracy(test_prediction.eval(), YArraysForTesting)\n",
    "\n",
    "#             else:\n",
    "#                 earlyStoppingCounter += 1\n",
    "\n",
    "#             if earlyStoppingCounter == 50:\n",
    "#                 break\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "        # print(session.run(W))\n",
    "        predictionResult = test_prediction.eval()\n",
    "        accResult = accuracy(predictionResult , YArraysForTesting)\n",
    "        penaltyValue = assymetricPredictionScore(predictionResult, YArraysForTesting, boundaries)\n",
    "#         print(W.eval())\n",
    "#         if accuracy_earlyStop > accResult:\n",
    "#             accuracy_result = accuracy_earlyStop\n",
    "#         else:\n",
    "        accuracy_result = accResult\n",
    "            \n",
    "        correctLableIndex = np.argmax(YArraysForTesting, 1)\n",
    "        predictionIndex = np.argmax(predictionResult, 1)\n",
    "        \n",
    "        precision = precision_score(correctLableIndex, predictionIndex, average='weighted')\n",
    "        recall = recall_score(correctLableIndex, predictionIndex, average='weighted')\n",
    "        f1Score = f1_score(correctLableIndex, predictionIndex, average='weighted')            \n",
    "        \n",
    "        return accuracy_result, penaltyValue, precision, recall, f1Score\n",
    "            \n",
    "    \n",
    "def assymetricPredictionScore(predictedLables, trueLables, boundaries):\n",
    "    xAxisPoints = np.linspace(rayleigh.ppf(0.01), rayleigh.ppf(0.99), 338)\n",
    "    #number of overal datapoints must stay the same all the time\n",
    "    maxState = 338\n",
    "\n",
    "    inverseDistrib = max(rayleigh.pdf(xAxisPoints)) - rayleigh.pdf(xAxisPoints)\n",
    "    minState = np.argmin(inverseDistrib)\n",
    "\n",
    "    underUtilizedSum = 0\n",
    "    overUtilizedSum = 0\n",
    "    numberOfUnderUtilizedStates = minState - 0\n",
    "    numberOfOverUtilizedStates = maxState - minState\n",
    "\n",
    "    xAxisPoints -= xAxisPoints[np.argmin(inverseDistrib)]\n",
    "\n",
    "    underUtilVal = numberOfUnderUtilizedStates / 100\n",
    "    overUtilVal = numberOfOverUtilizedStates / 100\n",
    "\n",
    "    correctLableIndex = np.argmax(trueLables, 1)\n",
    "    predictionIndex = np.argmax(predictedLables, 1)\n",
    "\n",
    "    diffPercentage = np.zeros(shape = (predictedLables.shape))\n",
    "\n",
    "    penalties = np.zeros(shape = (predictedLables.shape))\n",
    "\n",
    "    for index in range(predictedLables.shape[0]):\n",
    "        diffPercentage[index] = boundaries[correctLableIndex[index]] - boundaries[:]\n",
    "\n",
    "\n",
    "    for i in range(diffPercentage.shape[0]):\n",
    "        for j in range(diffPercentage.shape[1]):\n",
    "            if diffPercentage[i][j] > 0:\n",
    "                penalties[i][j] = inverseDistrib[minState + math.floor\n",
    "                                                  (diffPercentage[i][j] * overUtilVal)]\n",
    "            else:\n",
    "                penalties[i][j] = inverseDistrib[minState + math.floor\n",
    "                                                  (diffPercentage[i][j] * underUtilVal)]\n",
    "\n",
    "    sumOfPenalty = 0\n",
    "    for i in range(predictionIndex.shape[0]):\n",
    "        penalties[i] = penalties[i] / np.sum(penalties[i])\n",
    "        sumOfPenalty += penalties[i][predictionIndex[i]]\n",
    "\n",
    "    return sumOfPenalty\n",
    "    \n",
    "    \n",
    "def accuracy(predictedLables, trueLables):\n",
    "    import sys\n",
    "    np.set_printoptions(threshold=sys.maxsize)\n",
    "    correctLableIndex = np.argmax(trueLables, 1)\n",
    "    predictionIndex = np.argmax(predictedLables, 1)\n",
    "    errors = [0 for i in range(trueLables.shape[1])]\n",
    "    corrects = [0 for i in range(trueLables.shape[1])]\n",
    "    for i in range(len(correctLableIndex)):\n",
    "        if correctLableIndex[i] != predictionIndex[i]:\n",
    "            errors[correctLableIndex[i]] += 1\n",
    "            corrects[predictionIndex[i]] += 1\n",
    "\n",
    "    acc = np.float64(np.sum(correctLableIndex == predictionIndex)/predictedLables.shape[0])\n",
    "    return acc\n",
    "    \n",
    "    \n",
    "def assymetricLossFunction(prediction, correctLable, boundaries):\n",
    "    xAxisPoints = np.linspace(rayleigh.ppf(0.01), rayleigh.ppf(0.99), 338)\n",
    "    #number of overal datapoints must stay the same all the time\n",
    "    maxState = 338\n",
    "    inverseDistrib = max(rayleigh.pdf(xAxisPoints)) - rayleigh.pdf(xAxisPoints)\n",
    "    inverseDistrib = tf.constant(inverseDistrib)\n",
    "    xAxisPoints -= xAxisPoints[np.argmin(inverseDistrib)]\n",
    "    minState = np.argmin(inverseDistrib)\n",
    "    numberOfOverUtilizedStates = maxState - minState\n",
    "    numberOfUnderUtilizedStates = minState\n",
    "    minState = tf.constant(minState, tf.float32)\n",
    "    numberOfOverUtilizedStates = tf.constant(numberOfOverUtilizedStates, tf.float32)\n",
    "    numberOfUnderUtilizedStates = tf.constant(numberOfUnderUtilizedStates, tf.float32)\n",
    "\n",
    "    underUtilVal = numberOfUnderUtilizedStates / 100\n",
    "    overUtilVal = numberOfOverUtilizedStates / 100\n",
    "\n",
    "\n",
    "    boundaries = tf.constant(boundaries, tf.float32)\n",
    "    correctLableIndex = tf.argmax(correctLable, 1)\n",
    "\n",
    "    diffPercentage = []\n",
    "    for index in range(correctLableIndex.shape[0]):\n",
    "        diffPercentage.append(boundaries[correctLableIndex[index]] - boundaries[:])\n",
    "\n",
    "    diffPercentage = tf.stack(diffPercentage)\n",
    "\n",
    "    penalties = []\n",
    "\n",
    "    counter = 0\n",
    "    for i in range(diffPercentage.shape[0]):\n",
    "        for j in range(diffPercentage.shape[1]):\n",
    "            counter += 1\n",
    "\n",
    "            penalties.append(tf.cond(\n",
    "                    tf.greater(diffPercentage[i][j], 0),\n",
    "                    lambda: inverseDistrib[tf.dtypes.cast(minState + tf.math.floor\n",
    "                                                                   (tf.math.scalar_mul(diffPercentage[i][j],\n",
    "                                                                                       overUtilVal)), tf.int32)],\n",
    "                    lambda: inverseDistrib[tf.dtypes.cast(minState + tf.math.floor\n",
    "                                                                   (tf.math.scalar_mul\n",
    "                                                                    (diffPercentage[i][j], underUtilVal))\n",
    "                                                                   , tf.int32)]\n",
    "                    ))\n",
    "\n",
    "    penalties = tf.stack(penalties)\n",
    "    penalties = tf.dtypes.cast(penalties, tf.float32)\n",
    "    penalties = tf.reshape(penalties, diffPercentage.shape)\n",
    "    penalties = penalties / tf.norm(penalties)\n",
    "\n",
    "    # weights = tf.reduce_sum(penalties * (1-prediction), axis=1)\n",
    "    weights = (1 - penalties) * prediction\n",
    "    weights = weights / tf.norm(weights)\n",
    "    # print(correctLable)\n",
    "    # print(prediction)\n",
    "    # print(penalties)\n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels = correctLable, logits = weights)\n",
    "    # weighted_losses = tf.nn.softmax_cross_entropy_with_logits_v2(labels = penalties, logits = prediction)\n",
    "    # loss = tf.reduce_sum(weighted_losses)\n",
    "    # loss = tf.reduce_sum(penalties * prediction)\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Lumped Matrices with their Bandwidths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"/home/sepehr/thesis/APDataML/normalBoundaries_30min.pickle\"\n",
    "with open(name, 'rb') as handle:\n",
    "    normalLumping = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentageArray = []\n",
    "for i in range(48):\n",
    "    name = \"/home/sepehr/thesis/APDataML/pickles/normal_lumping_percentage_\" + str(i) + \".pickle\"\n",
    "    with open(name, 'rb') as handle:\n",
    "        percentageArray.append(pickle.load(handle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyResult = [np.inf for i in range(48)]\n",
    "penaltyResult = [np.inf for i in range(48)]\n",
    "precisionResult = [np.inf for i in range(48)]\n",
    "recallResult = [np.inf for i in range(48)]\n",
    "f1ScoreResult = [np.inf for i in range(48)]\n",
    "boundariesResult = [np.inf for i in range(48)]\n",
    "lumpAproxResult = [np.inf for i in range(48)]\n",
    "lumpErrorResult = [np.inf for i in range(48)]\n",
    "\n",
    "\n",
    "testDataFrame = {\"accuracy\": accuracyResult, \"penalty\": penaltyResult, \"precision\": precisionResult, \n",
    "                 \"recall\": recallResult, \"f1Score\": f1ScoreResult, \"boundaries\": boundariesResult, \n",
    "                 \"lumpAprox\": lumpAproxResult, \"lumpError\": lumpErrorResult}\n",
    "\n",
    "resultDataFrameWithPenalty = pd.DataFrame(testDataFrame)\n",
    "resultDataFrameWithPenalty = resultDataFrameWithPenalty.astype('object')\n",
    "\n",
    "resultDataFrameNoPenalty = pd.DataFrame(testDataFrame)\n",
    "resultDataFrameNoPenalty = resultDataFrameNoPenalty.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "start training set generation\n",
      "19075\n",
      "4769\n",
      "starting tensor\n",
      "Initialized\n",
      "Initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "start training set generation\n",
      "18820\n",
      "4706\n",
      "starting tensor\n",
      "Initialized\n",
      "Initialized\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-deef8bc64e2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m     accuracy_result, penaltyValue, precision, recall, f1Score = tensorFlowLossFunction(\n\u001b[1;32m     40\u001b[0m         \u001b[0mlossFunctionBoolean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXArraysForLearning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYArraysForLearning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXArraysForTesting\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         YArraysForTesting, boundaries)\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-026509f089ed>\u001b[0m in \u001b[0;36mtensorFlowLossFunction\u001b[0;34m(lossFuncBool, XArraysForLearning, YArraysForLearning, XArraysForTesting, YArraysForTesting, boundaries)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;31m#                 print(l)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "for timeIndex in range(5):\n",
    "    if len(normalLumping[timeIndex]) == 0:\n",
    "        continue\n",
    "    \n",
    "    print(timeIndex)\n",
    "    boundaries = np.array([])\n",
    "    for i in range(1, len(normalLumping[0][0][3])):\n",
    "        bound = normalLumping[0][0][3][i]\n",
    "        counter = 0\n",
    "        for j in range(len(percentageArray[0])):\n",
    "            if percentageArray[0][j][2] == False:\n",
    "                counter += 1\n",
    "            if counter == bound:\n",
    "                boundaries = np.append(boundaries, percentageArray[0][j][1])\n",
    "                break\n",
    "    boundaries = np.append(boundaries,100)\n",
    "    \n",
    "    XArraysForLearning, YArraysForLearning, XArraysForTesting, YArraysForTesting, boundaries = dataPreparation(\n",
    "        data, timeIndex, 30, boundaries)\n",
    "\n",
    "    print(\"starting tensor\")\n",
    "    lossFunctionBoolean = 0\n",
    "    accuracy_result, penaltyValue, precision, recall, f1Score = tensorFlowLossFunction(\n",
    "        lossFunctionBoolean, XArraysForLearning, YArraysForLearning, XArraysForTesting, \n",
    "        YArraysForTesting, boundaries)\n",
    "    \n",
    "    resultDataFrameNoPenalty.loc[timeIndex][\"accuracy\"] = accuracy_result\n",
    "    resultDataFrameNoPenalty.loc[timeIndex][\"penalty\"] = penaltyValue\n",
    "    resultDataFrameNoPenalty.loc[timeIndex][\"precision\"] = precision\n",
    "    resultDataFrameNoPenalty.loc[timeIndex][\"recall\"] = recall\n",
    "    resultDataFrameNoPenalty.loc[timeIndex][\"f1Score\"] = f1Score\n",
    "    resultDataFrameNoPenalty.loc[timeIndex][\"boundaries\"] = boundaries\n",
    "    resultDataFrameNoPenalty.loc[timeIndex][\"lumpAprox\"] = normalLumping[timeIndex][0][0]\n",
    "    resultDataFrameNoPenalty.loc[timeIndex][\"lumpError\"] = normalLumping[timeIndex][0][1]\n",
    "    \n",
    "    \n",
    "    lossFunctionBoolean = 1\n",
    "    accuracy_result, penaltyValue, precision, recall, f1Score = tensorFlowLossFunction(\n",
    "        lossFunctionBoolean, XArraysForLearning, YArraysForLearning, XArraysForTesting, \n",
    "        YArraysForTesting, boundaries)\n",
    "    \n",
    "    \n",
    "    resultDataFrameWithPenalty.loc[timeIndex][\"accuracy\"] = accuracy_result\n",
    "    resultDataFrameWithPenalty.loc[timeIndex][\"penalty\"] = penaltyValue\n",
    "    resultDataFrameWithPenalty.loc[timeIndex][\"precision\"] = precision\n",
    "    resultDataFrameWithPenalty.loc[timeIndex][\"recall\"] = recall\n",
    "    resultDataFrameWithPenalty.loc[timeIndex][\"f1Score\"] = f1Score\n",
    "    resultDataFrameWithPenalty.loc[timeIndex][\"boundaries\"] = boundaries\n",
    "    resultDataFrameWithPenalty.loc[timeIndex][\"lumpAprox\"] = normalLumping[timeIndex][0][0]\n",
    "    resultDataFrameWithPenalty.loc[timeIndex][\"lumpError\"] = normalLumping[timeIndex][0][1]\n",
    "    \n",
    "    print(resultDataFrameNoPenalty.loc[timeIndex])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy                                               0.954707\n",
      "penalty                                                 8.60518\n",
      "precision                                              0.949913\n",
      "recall                                                 0.950304\n",
      "f1Score                                                 0.95003\n",
      "boundaries    [23.13725490196077, 34.11764705882348, 50.1960...\n",
      "lumpAprox                                                     1\n",
      "lumpError                                                 40.08\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(resultDataFrameNoPenalty.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "epoch  0 0.8470450680272109\n",
      "epoch  1 0.9311224489795918\n",
      "epoch  2 0.935905612244898\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-97500aca9dfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m accuracy_result, penaltyValue, precision, recall, f1Score = tensorFlowLossFunction(\n\u001b[1;32m      2\u001b[0m     \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXArraysForLearning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYArraysForLearning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXArraysForTesting\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     YArraysForTesting, boundaries)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-2c0ea4b3bc50>\u001b[0m in \u001b[0;36mtensorFlowLossFunction\u001b[0;34m(lossFuncBool, XArraysForLearning, YArraysForLearning, XArraysForTesting, YArraysForTesting, boundaries)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;31m#                 print(l)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracy_result, penaltyValue, precision, recall, f1Score = tensorFlowLossFunction(\n",
    "    1, XArraysForLearning, YArraysForLearning, XArraysForTesting, \n",
    "    YArraysForTesting, boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "epoch  0 0.8470450680272109\n",
      "epoch  1 0.9311224489795918\n",
      "epoch  2 0.935905612244898\n",
      "epoch  3 0.9357993197278912\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-97500aca9dfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m accuracy_result, penaltyValue, precision, recall, f1Score = tensorFlowLossFunction(\n\u001b[1;32m      2\u001b[0m     \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXArraysForLearning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYArraysForLearning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXArraysForTesting\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     YArraysForTesting, boundaries)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-2c0ea4b3bc50>\u001b[0m in \u001b[0;36mtensorFlowLossFunction\u001b[0;34m(lossFuncBool, XArraysForLearning, YArraysForLearning, XArraysForTesting, YArraysForTesting, boundaries)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;31m#                 print(l)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracy_result, penaltyValue, precision, recall, f1Score = tensorFlowLossFunction(\n",
    "    1, XArraysForLearning, YArraysForLearning, XArraysForTesting, \n",
    "    YArraysForTesting, boundaries)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
