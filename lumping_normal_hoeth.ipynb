{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning:\n",
      "\n",
      "can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning:\n",
      "\n",
      "can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py:5747: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.TextIOWrapper name='/home/sepehr/.keras/keras.json' mode='r' encoding='UTF-8'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %% codecell\n",
    "import numpy as np\n",
    "import Plot as plot\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as offline\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "import os\n",
    "import scipy.spatial\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import matplotlib as plt\n",
    "import logging\n",
    "from scipy import signal\n",
    "import learningAlgs as classImportLA\n",
    "import dataManipulation as dataMan\n",
    "from itertools import permutations\n",
    "import importlib\n",
    "from datetime import timedelta\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.cluster import KMeans\n",
    "import timeIntervalPlotter as intervalPlotter\n",
    "import pysal\n",
    "import warnings\n",
    "import lumping_traditional as oldLumping\n",
    "import boundaryFull_SS_WeightedLumping as WLumping\n",
    "from importlib import reload\n",
    "from scipy.stats import rayleigh\n",
    "import dataManipulation as dataMan\n",
    "import matplotlib.pyplot as plt\n",
    "import processData as processData\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings('always')\n",
    "# <codecell>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the address of the collected data files (not alligned files or CSV files): /home/sepehr/thesis/data/500f80271400/\n",
      "['500f80271400.txt']\n",
      "here\n",
      "500f80271400.txt is in csvChecker\n",
      "\n",
      "we have the csv file: pulling out data\n",
      "\n",
      "   col1                time  CU\n",
      "0     0 2018-11-13 02:01:32  45\n",
      "1     1 2018-11-13 02:01:38  45\n",
      "2     2 2018-11-13 02:01:44  51\n",
      "3     3 2018-11-13 02:01:50  53\n",
      "4     4 2018-11-13 02:01:56  45\n",
      "now we have the processed data from pandas\n",
      "hello\n",
      "please enter how long would be the chunk minutes? 30\n",
      "removing weekends from the data\n",
      "done\n",
      "[[0.34180791 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#*******************************************************************************\n",
    "# %%codecell\n",
    "reload(classImportLA)\n",
    "dataFrame = processData.processingData()\n",
    "#address is: /home/netlab/Desktop/thesis/data/1node1-3-5/\n",
    "#/home/netlab/Desktop/thesis/data/500f80271400/\n",
    "data = dataFrame.copy() #copying the dataFrame to have a copy of not edited data\n",
    "\n",
    "print(\"hello\")\n",
    "# <codecell>\n",
    "\n",
    "#*******************************************************************************\n",
    "# %% codecell\n",
    "data = processData.dataFrameManipulation(data)\n",
    "numberOfStates = 255\n",
    "reload(processData)\n",
    "cuTrans = processData.markovianTransitionMatrixDegree1(data, numberOfStates, \"CU\")\n",
    "normalizedCuTrans = processData.normalizingTransMatrix(cuTrans)\n",
    "cuTrans_cpy = normalizedCuTrans.copy()\n",
    "\n",
    "arrExtra = [0]\n",
    "print(\"done\")\n",
    "def particling(x):\n",
    "    if (x[\"col1\"] - 1 not in data[\"col1\"]) or (x[\"col1\"] - 1 < 0):\n",
    "        arrExtra[0] = x[\"time\"]\n",
    "        return 0\n",
    "\n",
    "    elif x[\"timeIndex\"] != data[\"timeIndex\"][x[\"col1\"] - 1]:\n",
    "        arrExtra[0] = x[\"time\"]\n",
    "        return 0\n",
    "\n",
    "    else:\n",
    "        return ((x[\"time\"] - arrExtra[0]).seconds)/6\n",
    "\n",
    "data[\"periodParticle\"] = data.apply(lambda x: particling(x), axis = 1) #numbering each 6 seconds in the dataFrame\n",
    "\n",
    "print(cuTrans_cpy[0])\n",
    "# <codecell>\n",
    "#*******************************************************************************\n",
    "\n",
    "def bandwidthPercentage(vectorMatrix):\n",
    "    percentageIncreament = (100 / vectorMatrix.shape[0])\n",
    "    percentageMatrix = []\n",
    "    maxPercentage = 0\n",
    "    for j in range(vectorMatrix.shape[0]):\n",
    "        maxPercentage += percentageIncreament\n",
    "        percentageMatrix.append([[j], maxPercentage, False])\n",
    "\n",
    "    return percentageMatrix\n",
    "\n",
    "def reduceMatrixAllInOne(transitionMatrix):\n",
    "    reload(oldLumping)\n",
    "    percentageMatrix_list = bandwidthPercentage(transitionMatrix)\n",
    "    zero_cols_rows = []\n",
    "    #*************removing zeros from columns and rows (matrix reduction) ****************\n",
    "    for i in range(len(transitionMatrix)):\n",
    "        if (np.sum(transitionMatrix[i]) == 0) and (np.sum(transitionMatrix[:,i]) == 0):\n",
    "            zero_cols_rows.append(i)\n",
    "\n",
    "\n",
    "    irreducible_matrix = transitionMatrix.copy()\n",
    "    for i in range(len(zero_cols_rows) - 1, -1, -1):\n",
    "        irreducible_matrix = np.delete(irreducible_matrix, zero_cols_rows[i], axis = 0)\n",
    "        irreducible_matrix = np.delete(irreducible_matrix, zero_cols_rows[i], axis = 1)\n",
    "        percentageMatrix_list[zero_cols_rows[i]][2] = True\n",
    "\n",
    "\n",
    "    for i in range(len(percentageMatrix_list) - 1, 0, -1):\n",
    "        if (percentageMatrix_list[i][2] == True) and (percentageMatrix_list[i - 1][2] == True):\n",
    "            percentageMatrix_list[i - 1][0].extend(percentageMatrix_list[i][0])\n",
    "            percentageMatrix_list[i - 1][1] = percentageMatrix_list[i][1]\n",
    "            del percentageMatrix_list[i]\n",
    "\n",
    "    result = oldLumping.lumping(irreducible_matrix, percentageMatrix_list, False)\n",
    "\n",
    "\n",
    "\n",
    "def preparingMatrixForLumping(transitionMatrix):\n",
    "    reload(oldLumping)\n",
    "    percentageMatrix_list = bandwidthPercentage(transitionMatrix)\n",
    "    zero_cols_rows = []\n",
    "    #*************removing zeros from columns and rows (matrix reduction) ****************\n",
    "    for i in range(len(transitionMatrix)):\n",
    "        if (np.sum(transitionMatrix[i]) == 0) and (np.sum(transitionMatrix[:,i]) == 0):\n",
    "            zero_cols_rows.append(i)\n",
    "\n",
    "\n",
    "    irreducible_matrix = transitionMatrix.copy()\n",
    "    for i in range(len(zero_cols_rows) - 1, -1, -1):\n",
    "        irreducible_matrix = np.delete(irreducible_matrix, zero_cols_rows[i], axis = 0)\n",
    "        irreducible_matrix = np.delete(irreducible_matrix, zero_cols_rows[i], axis = 1)\n",
    "        percentageMatrix_list[zero_cols_rows[i]][2] = True\n",
    "\n",
    "\n",
    "    for i in range(len(percentageMatrix_list) - 1, 0, -1):\n",
    "        if (percentageMatrix_list[i][2] == True) and (percentageMatrix_list[i - 1][2] == True):\n",
    "            percentageMatrix_list[i - 1][0].extend(percentageMatrix_list[i][0])\n",
    "            percentageMatrix_list[i - 1][1] = percentageMatrix_list[i][1]\n",
    "            del percentageMatrix_list[i]\n",
    "\n",
    "    for i in range(len(irreducible_matrix)):\n",
    "        if np.sum(irreducible_matrix[i], dtype = np.float32) != 1.0:\n",
    "            print(np.sum(irreducible_matrix[i], dtype = np.float32))\n",
    "\n",
    "    return percentageMatrix_list, irreducible_matrix\n",
    "\n",
    "def lumpingStatesOneByOne(percentageMatrix_list, irreducible_matrix):\n",
    "\n",
    "    # savedResult = 0\n",
    "    result = oldLumping.lumping(irreducible_matrix, percentageMatrix_list, True)\n",
    "\n",
    "    min_degree, min_error, irreducible_matrix, best_sectors = result[0], result[1], result[2], result[3]\n",
    "\n",
    "    zero_cols_rows = []\n",
    "    for i in range(len(irreducible_matrix)):\n",
    "        if (np.sum(irreducible_matrix[i]) == 0) and (np.sum(irreducible_matrix[:,i]) == 0):\n",
    "            zero_cols_rows.append(i)\n",
    "\n",
    "    if len(zero_cols_rows) != 0:\n",
    "        for i in range(len(zero_cols_rows) - 1, -1, -1):\n",
    "            irreducible_matrix = np.delete(irreducible_matrix, zero_cols_rows[i], axis = 0)\n",
    "            irreducible_matrix = np.delete(irreducible_matrix, zero_cols_rows[i], axis = 1)\n",
    "\n",
    "        percentageMatrix_list = reduceMatrix(percentageMatrix_list, zero_cols_rows)\n",
    "\n",
    "    print(\"length of best lumped is: \", len(irreducible_matrix))\n",
    "\n",
    "    percentageMatrix_list = mergeStates(best_sectors, percentageMatrix_list)\n",
    "\n",
    "    for i in range(len(irreducible_matrix)):\n",
    "        if (np.sum(irreducible_matrix[i], dtype = np.float32) != 1.0):\n",
    "\n",
    "            print(i, np.sum(irreducible_matrix[i], dtype = np.float32))\n",
    "\n",
    "    for i in range(irreducible_matrix.shape[0]):\n",
    "        sum = 0\n",
    "        sum = np.sum(irreducible_matrix[i])\n",
    "        if sum != 0:\n",
    "            irreducible_matrix[i] = irreducible_matrix[i]/sum\n",
    "\n",
    "    for i in range(len(irreducible_matrix)):\n",
    "        if (np.sum(irreducible_matrix[i], dtype = np.float32) != 1.0):\n",
    "\n",
    "            print(i, np.sum(irreducible_matrix[i], dtype = np.float32))\n",
    "\n",
    "    count = 0\n",
    "    for i in range(len(percentageMatrix_list)):\n",
    "        if percentageMatrix_list[i][2] == False:\n",
    "            count += 1\n",
    "    print(\"percentageMatrix length is: \", count)\n",
    "\n",
    "    return(percentageMatrix_list, irreducible_matrix)\n",
    "\n",
    "    # if len(irreducible_matrix) == 26:\n",
    "        # break\n",
    "    # result = oldLumping.lumping(irreducible_matrix, percentageMatrix_list, False)\n",
    "    # return result\n",
    "\n",
    "def reduceMatrix(percentageMatrix, zero_cols_rows):\n",
    "    index_in_percentage_matrix = np.inf\n",
    "    counter = 0\n",
    "    for x in range(len(zero_cols_rows)):\n",
    "        for i in range(len(percentageMatrix)):\n",
    "            if percentageMatrix[i][2] == False:\n",
    "                if zero_cols_rows[x] == counter:\n",
    "                    index_in_percentage_matrix = i\n",
    "                    break\n",
    "                counter += 1\n",
    "        percentageMatrix[index_in_percentage_matrix][2] = True\n",
    "        if index_in_percentage_matrix == (len(percentageMatrix) - 1):\n",
    "            if percentageMatrix[index_in_percentage_matrix - 1][2] == True:\n",
    "                percentageMatrix[index_in_percentage_matrix - 1][0].extend(\n",
    "                    percentageMatrix[index_in_percentage_matrix][0])\n",
    "\n",
    "                percentageMatrix[index_in_percentage_matrix - 1][1] = percentageMatrix[index_in_percentage_matrix][1]\n",
    "                del percentageMatrix[index_in_percentage_matrix]\n",
    "\n",
    "        elif index_in_percentage_matrix == 0:\n",
    "            if percentageMatrix[index_in_percentage_matrix + 1][2] == True:\n",
    "                percentageMatrix[index_in_percentage_matrix][0].extend(\n",
    "                    percentageMatrix[index_in_percentage_matrix + 1][0])\n",
    "\n",
    "                percentageMatrix[index_in_percentage_matrix][1] = percentageMatrix[index_in_percentage_matrix + 1][1]\n",
    "                del percentageMatrix[index_in_percentage_matrix + 1]\n",
    "\n",
    "        else:\n",
    "            if (percentageMatrix[index_in_percentage_matrix - 1][2] == True) and (\n",
    "                percentageMatrix[index_in_percentage_matrix + 1][2] == True):\n",
    "                leftside_bandwidth_val = 0\n",
    "                rightside_bandwidth_val = 0\n",
    "                if (index_in_percentage_matrix - 1) != 0:\n",
    "                    leftside_bandwidth_val = percentageMatrix[index_in_percentage_matrix][1] - percentageMatrix[index_in_percentage_matrix - 2][1]\n",
    "                else:\n",
    "                    leftside_bandwidth_val = percentageMatrix[index_in_percentage_matrix][1]\n",
    "                rightside_bandwidth_val = percentageMatrix[index_in_percentage_matrix + 1][1] - percentageMatrix[index_in_percentage_matrix - 1][1]\n",
    "\n",
    "                if leftside_bandwidth_val <= rightside_bandwidth_val:\n",
    "                    percentageMatrix[index_in_percentage_matrix - 1][0].extend(\n",
    "                        percentageMatrix[index_in_percentage_matrix][0])\n",
    "\n",
    "                    percentageMatrix[index_in_percentage_matrix - 1][1] = percentageMatrix[index_in_percentage_matrix][1]\n",
    "                    del percentageMatrix[index_in_percentage_matrix]\n",
    "\n",
    "                else:\n",
    "                    percentageMatrix[index_in_percentage_matrix][0].extend(\n",
    "                        percentageMatrix[index_in_percentage_matrix + 1][0])\n",
    "\n",
    "                    percentageMatrix[index_in_percentage_matrix][1] = percentageMatrix[index_in_percentage_matrix + 1][1]\n",
    "                    del percentageMatrix[index_in_percentage_matrix + 1]\n",
    "\n",
    "            elif (percentageMatrix[index_in_percentage_matrix - 1][2] == True) and (\n",
    "                percentageMatrix[index_in_percentage_matrix + 1][2] == False):\n",
    "\n",
    "                percentageMatrix[index_in_percentage_matrix - 1][0].extend(\n",
    "                    percentageMatrix[index_in_percentage_matrix][0])\n",
    "\n",
    "                percentageMatrix[index_in_percentage_matrix - 1][1] = percentageMatrix[index_in_percentage_matrix][1]\n",
    "                del percentageMatrix[index_in_percentage_matrix]\n",
    "\n",
    "            elif (percentageMatrix[index_in_percentage_matrix - 1][2] == False) and (\n",
    "                percentageMatrix[index_in_percentage_matrix + 1][2] == True):\n",
    "\n",
    "                percentageMatrix[index_in_percentage_matrix][0].extend(\n",
    "                    percentageMatrix[index_in_percentage_matrix + 1][0])\n",
    "\n",
    "                percentageMatrix[index_in_percentage_matrix][1] = percentageMatrix[index_in_percentage_matrix + 1][1]\n",
    "                del percentageMatrix[index_in_percentage_matrix + 1]\n",
    "\n",
    "    return percentageMatrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mergeStates(best_sectors, percentageMatrix):\n",
    "    False_state_in_percentageMatrix = np.inf\n",
    "    for i in range(1, len(best_sectors)):\n",
    "        if best_sectors[i] - best_sectors[i - 1] == 2:\n",
    "            False_state_in_percentageMatrix = best_sectors[i]\n",
    "            #it means states number (whole_subset[i] - 1) and (whole_subset[i] - 2) should merge\n",
    "            #it is also the (whole_subset[i]) False and (whole_subset[i] - 1) False in percentageMatrix\n",
    "            break\n",
    "\n",
    "    index1_in_percentage_matrix = np.inf\n",
    "    index2_in_percentage_matrix = np.inf\n",
    "    counter = 0\n",
    "    for i in range(len(percentageMatrix)):\n",
    "        if percentageMatrix[i][2] == False:\n",
    "            counter += 1\n",
    "            if counter == (False_state_in_percentageMatrix - 1):\n",
    "                index1_in_percentage_matrix = i\n",
    "            elif counter == False_state_in_percentageMatrix:\n",
    "                index2_in_percentage_matrix = i\n",
    "                break\n",
    "\n",
    "    # print(\"indices are: \", index1_in_percentage_matrix, index2_in_percentage_matrix)\n",
    "    # print(\"values of indices: \", percentageMatrix[index1_in_percentage_matrix])\n",
    "    # print(\"values of indices: \", percentageMatrix[index2_in_percentage_matrix])\n",
    "    if (index2_in_percentage_matrix) == (index1_in_percentage_matrix + 1):\n",
    "        percentageMatrix[index1_in_percentage_matrix][0].extend(\n",
    "            percentageMatrix[index2_in_percentage_matrix][0])\n",
    "\n",
    "        percentageMatrix[index1_in_percentage_matrix][1] = percentageMatrix[\n",
    "            index2_in_percentage_matrix][1]\n",
    "\n",
    "        del percentageMatrix[index2_in_percentage_matrix]\n",
    "\n",
    "    elif (index2_in_percentage_matrix) == (index1_in_percentage_matrix + 2):\n",
    "        percentageMatrix[index1_in_percentage_matrix + 1][0].extend(\n",
    "            percentageMatrix[index2_in_percentage_matrix][0])\n",
    "\n",
    "        percentageMatrix[index1_in_percentage_matrix][0].extend(\n",
    "            percentageMatrix[index1_in_percentage_matrix + 1][0])\n",
    "\n",
    "        percentageMatrix[index1_in_percentage_matrix][1] = percentageMatrix[\n",
    "            index2_in_percentage_matrix][1]\n",
    "\n",
    "        del percentageMatrix[index2_in_percentage_matrix]\n",
    "        del percentageMatrix[index1_in_percentage_matrix + 1]\n",
    "\n",
    "    return percentageMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lumping_traditional' from '/home/sepehr/thesis/APDataML/lumping_traditional.py'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(oldLumping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  13048\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  13048\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  12838\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  13048\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "we have these many sectors to check:  13048\n"
     ]
    }
   ],
   "source": [
    "for i in range(20, 25):\n",
    "    percentageMatrix_list, irreducible_matrix = preparingMatrixForLumping(cuTrans_cpy[i])\n",
    "    result = oldLumping.lumping(irreducible_matrix, percentageMatrix_list, False)\n",
    "    nameResult = \"/home/sepehr/thesis/APDataML/pickles/5normal_lumping_result_\" + str(i) + \".pickle\"\n",
    "    with open(nameResult, 'wb') as handle:\n",
    "        pickle.dump(result, handle)\n",
    "    namePercent = \"/home/sepehr/thesis/APDataML/pickles/5normal_lumping_percentage_\" + str(i) + \".pickle\"\n",
    "    with open(namePercent, 'wb') as handle:\n",
    "        pickle.dump(percentageMatrix_list, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  12838\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  13048\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  12710\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  13048\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  13048\n"
     ]
    }
   ],
   "source": [
    "for i in range(25, 30):\n",
    "    percentageMatrix_list, irreducible_matrix = preparingMatrixForLumping(cuTrans_cpy[i])\n",
    "    result = oldLumping.lumping(irreducible_matrix, percentageMatrix_list, False)\n",
    "    nameResult = \"/home/sepehr/thesis/APDataML/pickles/5normal_lumping_result_\" + str(i) + \".pickle\"\n",
    "    with open(nameResult, 'wb') as handle:\n",
    "        pickle.dump(result, handle)\n",
    "    namePercent = \"/home/sepehr/thesis/APDataML/pickles/5normal_lumping_percentage_\" + str(i) + \".pickle\"\n",
    "    with open(namePercent, 'wb') as handle:\n",
    "        pickle.dump(percentageMatrix_list, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  13048\n",
      "0.9999999\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  12838\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  12838\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "we have these many sectors to check:  13048\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  13048\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  12158\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "we have these many sectors to check:  12328\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  9192\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  12085\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "we have these many sectors to check:  12004\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  9197\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.9999999\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  7820\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  5627\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "we have these many sectors to check:  2846\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "1.0000001\n",
      "0.99999994\n",
      "we have these many sectors to check:  0\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.9999999\n",
      "0.99999994\n",
      "we have these many sectors to check:  4673\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "we have these many sectors to check:  613\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "we have these many sectors to check:  625\n"
     ]
    }
   ],
   "source": [
    "for i in range(30, 48):\n",
    "    percentageMatrix_list, irreducible_matrix = preparingMatrixForLumping(cuTrans_cpy[i])\n",
    "    result = oldLumping.lumping(irreducible_matrix, percentageMatrix_list, False)\n",
    "    nameResult = \"/home/sepehr/thesis/APDataML/pickles/5normal_lumping_result_\" + str(i) + \".pickle\"\n",
    "    with open(nameResult, 'wb') as handle:\n",
    "        pickle.dump(result, handle)\n",
    "    namePercent = \"/home/sepehr/thesis/APDataML/pickles/5normal_lumping_percentage_\" + str(i) + \".pickle\"\n",
    "    with open(namePercent, 'wb') as handle:\n",
    "        pickle.dump(percentageMatrix_list, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "we have these many sectors to check:  6232\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  3723\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  1044\n",
      "0.9999999\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  490\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  1088\n",
      "0.9999999\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  1775\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  0\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  308\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  338\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "we have these many sectors to check:  0\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "we have these many sectors to check:  24\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  0\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "we have these many sectors to check:  0\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "we have these many sectors to check:  3870\n",
      "0.99999994\n",
      "0.99999994\n",
      "we have these many sectors to check:  10390\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  10159\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  7173\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  9722\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  9957\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  12290\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    percentageMatrix_list, irreducible_matrix = preparingMatrixForLumping(cuTrans_cpy[i])\n",
    "    result = oldLumping.lumping(irreducible_matrix, percentageMatrix_list, False)\n",
    "    nameResult = \"/home/sepehr/thesis/APDataML/pickles/5normal_lumping_result_\" + str(i) + \".pickle\"\n",
    "    with open(nameResult, 'wb') as handle:\n",
    "        pickle.dump(result, handle)\n",
    "    namePercent = \"/home/sepehr/thesis/APDataML/pickles/5normal_lumping_percentage_\" + str(i) + \".pickle\"\n",
    "    with open(namePercent, 'wb') as handle:\n",
    "        pickle.dump(percentageMatrix_list, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "arrayOfLumpes = []\n",
    "indexesOfCandidates = [[] for i in range(48)]\n",
    "for timeIndex in range(48):\n",
    "    print(timeIndex)\n",
    "    name = \"/home/sepehr/thesis/APDataML/pickles/5normal_lumping_result_\" + str(timeIndex) + \".pickle\"\n",
    "    with open(name, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "    \n",
    "    if len(b) > 0:\n",
    "        minDegree = np.inf        \n",
    "        for i in range(len(b)):\n",
    "            if b[i][0] < minDegree:\n",
    "                minDegree = b[i][0]\n",
    "\n",
    "        minError = np.inf\n",
    "        for i in range(len(b)):\n",
    "            if b[i][0] == minDegree and b[i][1] < minError:\n",
    "                minError = b[i][1]\n",
    "\n",
    "        for i in range(len(b)):\n",
    "            if b[i][0] == minDegree and b[i][1] == minError:\n",
    "                indexesOfCandidates[timeIndex].append(b[i])\n",
    "\n",
    "name = \"/home/sepehr/thesis/APDataML/5normalBoundaries.pickle\"\n",
    "with open(name, 'wb') as handle:\n",
    "    pickle.dump(indexesOfCandidates, handle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  366134\n",
      "0.9999999\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  337462\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  337462\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "we have these many sectors to check:  366134\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  366134\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  342500\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "we have these many sectors to check:  337088\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  175582\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  311290\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "we have these many sectors to check:  341818\n"
     ]
    }
   ],
   "source": [
    "for i in range(30, 40):\n",
    "    percentageMatrix_list, irreducible_matrix = preparingMatrixForLumping(cuTrans_cpy[i])\n",
    "    result = oldLumping.lumping(irreducible_matrix, percentageMatrix_list, False)\n",
    "    name = \"/home/sepehr/thesis/APDataML/pickles/normal_lumping_result_\" + str(i) + \".pickle\"\n",
    "    with open(name, 'wb') as handle:\n",
    "        pickle.dump(result, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  264788\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  256785\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  279766\n"
     ]
    }
   ],
   "source": [
    "for i in range(17, 20):\n",
    "    percentageMatrix_list, irreducible_matrix = preparingMatrixForLumping(cuTrans_cpy[i])\n",
    "    result = oldLumping.lumping(irreducible_matrix, percentageMatrix_list, False)\n",
    "    name = \"/home/sepehr/thesis/APDataML/pickles/normal_lumping_result_\" + str(i) + \".pickle\"\n",
    "    with open(name, 'wb') as handle:\n",
    "        pickle.dump(result, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99999994\n",
      "0.99999994\n",
      "we have these many sectors to check:  195218\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  167340\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  98428\n"
     ]
    }
   ],
   "source": [
    "for i in range(14, 17):\n",
    "    percentageMatrix_list, irreducible_matrix = preparingMatrixForLumping(cuTrans_cpy[i])\n",
    "    result = oldLumping.lumping(irreducible_matrix, percentageMatrix_list, False)\n",
    "    name = \"/home/sepehr/thesis/APDataML/pickles/normal_lumping_result_\" + str(i) + \".pickle\"\n",
    "    with open(name, 'wb') as handle:\n",
    "        pickle.dump(result, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lumping_traditional' from '/home/sepehr/thesis/APDataML/lumping_traditional.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(oldLumping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  8800\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "we have these many sectors to check:  0\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  0\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "we have these many sectors to check:  1776\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "1.0000001\n",
      "0.99999994\n",
      "we have these many sectors to check:  13156\n"
     ]
    }
   ],
   "source": [
    "for i in [6, 9, 11, 12, 44]:\n",
    "    percentageMatrix_list, irreducible_matrix = preparingMatrixForLumping(cuTrans_cpy[i])\n",
    "    result = oldLumping.lumping(irreducible_matrix, percentageMatrix_list, False)\n",
    "    name = \"/home/sepehr/thesis/APDataML/pickles/normal_lumping_result_\" + str(i) + \".pickle\"\n",
    "    with open(name, 'wb') as handle:\n",
    "        pickle.dump(result, handle)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n"
     ]
    }
   ],
   "source": [
    "indexesOfCandidates = [[] for i in range(48)]\n",
    "print(indexesOfCandidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "arrayOfLumpes = []\n",
    "indexesOfCandidates = [[] for i in range(48)]\n",
    "for timeIndex in range(48):\n",
    "    print(timeIndex)\n",
    "    name = \"/home/sepehr/thesis/APDataML/normalPickles/normal_lumping_result_\" + str(timeIndex) + \".pickle\"\n",
    "    with open(name, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "    \n",
    "    if len(b) > 0:\n",
    "        minDegree = np.inf        \n",
    "        for i in range(len(b)):\n",
    "            if b[i][0] < minDegree:\n",
    "                minDegree = b[i][0]\n",
    "\n",
    "        minError = np.inf\n",
    "        for i in range(len(b)):\n",
    "            if b[i][0] == minDegree and b[i][1] < minError:\n",
    "                minError = b[i][1]\n",
    "\n",
    "        for i in range(len(b)):\n",
    "            if b[i][0] == minDegree and b[i][1] == minError:\n",
    "                indexesOfCandidates[timeIndex].append(b[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexesOfCandidates\n",
    "name = \"/home/sepehr/thesis/APDataML/normalBoundaries-30min.pickle\"\n",
    "with open(name, 'wb') as handle:\n",
    "    pickle.dump(indexesOfCandidates, handle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"/home/sepehr/thesis/APDataML/normalBoundaries_30min.pickle\"\n",
    "with open(name, 'rb') as handle:\n",
    "    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0,\n",
       "  40.0799560546875,\n",
       "  array([[0.83597884, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        ],\n",
       "         [0.3968254 , 0.20052083, 0.03125   , 0.        , 0.        ,\n",
       "          0.        ],\n",
       "         [0.3       , 0.14285714, 0.2       , 0.        , 0.        ,\n",
       "          0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.25      , 0.        ,\n",
       "          0.        ],\n",
       "         [0.33333333, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        ]]),\n",
       "  [-1, 19, 30, 46, 60, 67, 79])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
