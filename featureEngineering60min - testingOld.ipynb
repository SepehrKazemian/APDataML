{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Plot as plot\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as offline\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "import os\n",
    "import scipy.spatial\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import matplotlib as plt\n",
    "import logging\n",
    "from scipy import signal\n",
    "import learningAlgs as classImportLA\n",
    "import dataManipulation as dataMan\n",
    "from itertools import permutations\n",
    "import importlib\n",
    "from datetime import timedelta\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.cluster import KMeans\n",
    "import timeIntervalPlotter as intervalPlotter\n",
    "import pysal\n",
    "import warnings\n",
    "import lumping_traditional as oldLumping\n",
    "import boundaryFull_SS_WeightedLumping as WLumping\n",
    "from importlib import reload\n",
    "from scipy.stats import rayleigh\n",
    "import dataManipulation as dataMan\n",
    "import matplotlib.pyplot as plt\n",
    "import processData as processData\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from random import shuffle\n",
    "\n",
    "warnings.filterwarnings('always')\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Data and Creating Transition Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the address of the collected data files (not alligned files or CSV files): /home/sepehr/thesis/data/500f80271400/\n",
      "['500f80271400.txt']\n",
      "here\n",
      "500f80271400.txt is in csvChecker\n",
      "\n",
      "we have the csv file: pulling out data\n",
      "\n",
      "   col1                time  CU\n",
      "0     0 2018-11-13 02:01:32  45\n",
      "1     1 2018-11-13 02:01:38  45\n",
      "2     2 2018-11-13 02:01:44  51\n",
      "3     3 2018-11-13 02:01:50  53\n",
      "4     4 2018-11-13 02:01:56  45\n",
      "now we have the processed data from pandas\n",
      "please enter how long would be the chunk minutes? 60\n",
      "removing weekends from the data\n"
     ]
    }
   ],
   "source": [
    "dataFrame = processData.processingData()\n",
    "#address is: /home/netlab/Desktop/thesis/data/1node1-3-5/\n",
    "#/home/netlab/Desktop/thesis/data/500f80271400/\n",
    "data = dataFrame.copy() #copying the dataFrame to have a copy of not edited data\n",
    "\n",
    "data = processData.dataFrameManipulation(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfStates = 255\n",
    "cuTrans_60min = processData.markovianTransitionMatrixDegree1(data, numberOfStates, \"CU\")\n",
    "normalizedCuTrans_60min = processData.normalizingTransMatrix(cuTrans_60min)\n",
    "cuTrans_cpy = normalizedCuTrans_60min.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "for x in range(max(data[\"timeIndex\"]) + 1):\n",
    "    print(x)\n",
    "    maximum = 0\n",
    "    counter = 1\n",
    "    for i in range(len(cuTrans_cpy[x])):\n",
    "        if int(np.sum(cuTrans_cpy[x][i])) != 0:\n",
    "            if (counter > maximum):\n",
    "                maximum = counter\n",
    "            counter = 1\n",
    "        elif int(np.sum(cuTrans_cpy[x][i])) == 0 and int(np.sum(cuTrans_cpy[x].T[i])) == 0:\n",
    "            counter += 1\n",
    "    if (max(maximum, counter)/255 * 100) > 25:\n",
    "        print(x, max(maximum, counter)/255 * 100)\n",
    "        print(\"this tau value does not work for all time-intervals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating days and shuffling with seed to create Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dayCalculator(x):\n",
    "    years = x[\"time\"].year - data[\"time\"][0].year\n",
    "    months = x[\"time\"].month - data[\"time\"][0].month\n",
    "    days = x[\"time\"].day - data[\"time\"][0].day\n",
    "    return ((years*12*30) + (months*30) + days)\n",
    "data[\"day\"] = data.apply(lambda x: dayCalculator(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueDays = []\n",
    "uniqueDays.extend(data.apply(lambda x: x[\"day\"] if x[\"day\"] not in uniqueDays else np.inf, axis = 1))\n",
    "uniqueDays = list(set(uniqueDays))\n",
    "random.Random(0).shuffle(uniqueDays)\n",
    "\n",
    "days30 = uniqueDays[0:30]\n",
    "data_within_30Days = data.loc[data[\"day\"].isin(days30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfStates = 255\n",
    "cuTrans_30Days = processData.markovianTransitionMatrixDegree1(data_within_30Days, numberOfStates, \"CU\")\n",
    "normalizedCuTrans_30Days = processData.normalizingTransMatrix(cuTrans_30Days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "pd.options.mode.chained_assignment = None\n",
    "steadyState_30days = np.zeros(shape=(normalizedCuTrans_30Days.shape[0],\n",
    "                                     normalizedCuTrans_30Days.shape[1]))\n",
    "for i in range(normalizedCuTrans_30Days.shape[0]):\n",
    "    steadyState_30days[i] = abs(pysal.spatial_dynamics.ergodic.steady_state(normalizedCuTrans_30Days[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(data[\"timeIndex\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(max(data[\"timeIndex\"])+1):\n",
    "    data[\"corr\" + str(x + 1)] = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31, 10, 15, 9, 185, 17, 1, 252, 257, 195, 22, 205, 191, 167, 238, 2, 184, 246, 224, 210, 25, 8, 32, 14, 201, 147, 30, 146, 240, 161, 254, 236, 177, 264, 245, 141, 153, 219, 178, 18, 243, 216, 4, 28, 21, 29, 148, 223, 198, 211, 218, 189, 215, 35, 260, 183, 259, 0, 217, 154, 199, 253, 3, 258, 197, 251, 36, 164, 196, 250, 247, 202, 168, 11, 239, 163, 24, 225, 212, 149, 237, 16, 244, 160, 23, 208, 37, 222, 182, 203, 162, 190, 204, 209, 150, 7, 192, 188]\n",
      "31\n",
      "10\n",
      "15\n",
      "9\n",
      "185\n",
      "17\n",
      "1\n",
      "252\n",
      "257\n",
      "195\n",
      "22\n",
      "205\n",
      "191\n",
      "167\n",
      "238\n",
      "2\n",
      "184\n",
      "246\n",
      "224\n",
      "210\n",
      "25\n",
      "8\n",
      "32\n",
      "14\n",
      "201\n",
      "147\n",
      "30\n",
      "146\n",
      "240\n",
      "161\n",
      "254\n",
      "236\n",
      "177\n",
      "264\n",
      "245\n",
      "141\n",
      "153\n",
      "219\n",
      "178\n",
      "18\n",
      "243\n",
      "216\n",
      "4\n",
      "28\n",
      "21\n",
      "29\n",
      "148\n",
      "223\n",
      "198\n",
      "211\n",
      "218\n",
      "189\n",
      "215\n",
      "35\n",
      "260\n",
      "183\n",
      "259\n",
      "0\n",
      "217\n",
      "154\n",
      "199\n",
      "253\n",
      "3\n",
      "258\n",
      "197\n",
      "251\n",
      "36\n",
      "164\n",
      "196\n",
      "250\n",
      "247\n",
      "202\n",
      "168\n",
      "11\n",
      "239\n",
      "163\n",
      "24\n",
      "225\n",
      "212\n",
      "149\n",
      "237\n",
      "16\n",
      "244\n",
      "160\n",
      "23\n",
      "208\n",
      "37\n",
      "222\n",
      "182\n",
      "203\n",
      "162\n",
      "190\n",
      "204\n",
      "209\n",
      "150\n",
      "7\n",
      "192\n",
      "188\n"
     ]
    }
   ],
   "source": [
    "print(uniqueDays)\n",
    "for j in uniqueDays:\n",
    "    print(j)\n",
    "    for i in range(max(data[\"timeIndex\"])+1):\n",
    "        data_correlation = data.loc[(data[\"timeIndex\"] == i) & (data[\"day\"] == j)].copy()\n",
    "        if len(data_correlation) == 0:\n",
    "            continue\n",
    "        cuTran_corr = processData.markovianTransitionMatrixDegree1(data_correlation, numberOfStates, \"CU\")\n",
    "        for x in range(cuTran_corr[-1].shape[0]):\n",
    "            if np.sum(cuTran_corr[-1][x]) == 0:\n",
    "                continue\n",
    "            cuTran_corr[-1][x] = cuTran_corr[-1][x] / np.sum(cuTran_corr[-1][x])\n",
    "        steadyState_corr = abs(pysal.spatial_dynamics.ergodic.steady_state(cuTran_corr[-1]))\n",
    "\n",
    "        steadyState_corr_normalize = (steadyState_corr - np.mean(steadyState_corr)) / (\n",
    "            np.std(steadyState_corr) * len(steadyState_corr))\n",
    "        \n",
    "        correlationDistance = []\n",
    "        \n",
    "        for x in range(max(data[\"timeIndex\"])+1):\n",
    "            ss_normalize = (steadyState_30days[x] - np.mean(steadyState_30days[x])) / (\n",
    "                np.std(steadyState_30days[x]))\n",
    "            data[\"corr\" + str(x + 1)].loc[(data[\"timeIndex\"] == i) & (data[\"day\"] == j)] = signal.correlate(\n",
    "                steadyState_corr_normalize, ss_normalize, mode=\"valid\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Staionary Process Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_data = data.copy()\n",
    "data[\"logDiff\"] = np.inf\n",
    "data[\"log\"] = np.inf\n",
    "data[\"normalLogDiff\"] = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(np.max(data[\"timeIndex\"]) + 1):\n",
    "    dataTimeIndex = data.loc[data[\"timeIndex\"] == i]\n",
    "    dataTimeIndex[\"log\"] = np.log(dataTimeIndex[\"CU\"])\n",
    "    dataTimeIndex = dataTimeIndex.loc[dataTimeIndex[\"log\"] != -np.inf]\n",
    "    dataTimeIndex = dataTimeIndex.loc[dataTimeIndex[\"log\"] != np.inf]\n",
    "    dataTimeIndex = dataTimeIndex.dropna()\n",
    "    \n",
    "    dataTimeIndex[\"logDiff\"] = dataTimeIndex[\"log\"].diff()\n",
    "    dataTimeIndex = dataTimeIndex.loc[dataTimeIndex[\"logDiff\"] != -np.inf]\n",
    "    dataTimeIndex = dataTimeIndex.loc[dataTimeIndex[\"logDiff\"] != -np.inf]\n",
    "    dataTimeIndex = dataTimeIndex.dropna()\n",
    "    \n",
    "    dataTimeIndex[\"normalLogDiff\"] = dataTimeIndex[\"logDiff\"] / np.max(dataTimeIndex[\"logDiff\"])\n",
    "    data.loc[data[\"timeIndex\"] == i] = dataTimeIndex\n",
    "    \n",
    "data = data.loc[data[\"log\"] != np.inf]\n",
    "data = data.loc[data[\"log\"] != -np.inf]\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Feature Engineered DataFrame into a Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"timeIndex\"] = data[\"timeIndex\"].astype(int)\n",
    "data.to_pickle(\"60min_featureEngineer.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>time</th>\n",
       "      <th>CU</th>\n",
       "      <th>CU/255</th>\n",
       "      <th>timeIndex</th>\n",
       "      <th>weekDay</th>\n",
       "      <th>day</th>\n",
       "      <th>corr1</th>\n",
       "      <th>corr2</th>\n",
       "      <th>corr3</th>\n",
       "      <th>...</th>\n",
       "      <th>corr18</th>\n",
       "      <th>corr19</th>\n",
       "      <th>corr20</th>\n",
       "      <th>corr21</th>\n",
       "      <th>corr22</th>\n",
       "      <th>corr23</th>\n",
       "      <th>corr24</th>\n",
       "      <th>logDiff</th>\n",
       "      <th>log</th>\n",
       "      <th>normalLogDiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-11-12 19:01:38</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.798863</td>\n",
       "      <td>0.787328</td>\n",
       "      <td>0.814917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510812</td>\n",
       "      <td>0.518949</td>\n",
       "      <td>0.595878</td>\n",
       "      <td>0.733483</td>\n",
       "      <td>0.746124</td>\n",
       "      <td>0.759237</td>\n",
       "      <td>0.768665</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.806662</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-11-12 19:01:44</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.798863</td>\n",
       "      <td>0.787328</td>\n",
       "      <td>0.814917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510812</td>\n",
       "      <td>0.518949</td>\n",
       "      <td>0.595878</td>\n",
       "      <td>0.733483</td>\n",
       "      <td>0.746124</td>\n",
       "      <td>0.759237</td>\n",
       "      <td>0.768665</td>\n",
       "      <td>0.125163</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>0.052939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2018-11-12 19:01:50</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.207843</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.798863</td>\n",
       "      <td>0.787328</td>\n",
       "      <td>0.814917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510812</td>\n",
       "      <td>0.518949</td>\n",
       "      <td>0.595878</td>\n",
       "      <td>0.733483</td>\n",
       "      <td>0.746124</td>\n",
       "      <td>0.759237</td>\n",
       "      <td>0.768665</td>\n",
       "      <td>0.038466</td>\n",
       "      <td>3.970292</td>\n",
       "      <td>0.016270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2018-11-12 19:01:56</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.798863</td>\n",
       "      <td>0.787328</td>\n",
       "      <td>0.814917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510812</td>\n",
       "      <td>0.518949</td>\n",
       "      <td>0.595878</td>\n",
       "      <td>0.733483</td>\n",
       "      <td>0.746124</td>\n",
       "      <td>0.759237</td>\n",
       "      <td>0.768665</td>\n",
       "      <td>-0.163629</td>\n",
       "      <td>3.806662</td>\n",
       "      <td>-0.069209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-11-12 19:02:02</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.798863</td>\n",
       "      <td>0.787328</td>\n",
       "      <td>0.814917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510812</td>\n",
       "      <td>0.518949</td>\n",
       "      <td>0.595878</td>\n",
       "      <td>0.733483</td>\n",
       "      <td>0.746124</td>\n",
       "      <td>0.759237</td>\n",
       "      <td>0.768665</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.806662</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1                time    CU    CU/255  timeIndex  weekDay  day  \\\n",
       "1   1.0 2018-11-12 19:01:38  45.0  0.176471         19      0.0  0.0   \n",
       "2   2.0 2018-11-12 19:01:44  51.0  0.200000         19      0.0  0.0   \n",
       "3   3.0 2018-11-12 19:01:50  53.0  0.207843         19      0.0  0.0   \n",
       "4   4.0 2018-11-12 19:01:56  45.0  0.176471         19      0.0  0.0   \n",
       "5   5.0 2018-11-12 19:02:02  45.0  0.176471         19      0.0  0.0   \n",
       "\n",
       "      corr1     corr2     corr3  ...    corr18    corr19    corr20    corr21  \\\n",
       "1  0.798863  0.787328  0.814917  ...  0.510812  0.518949  0.595878  0.733483   \n",
       "2  0.798863  0.787328  0.814917  ...  0.510812  0.518949  0.595878  0.733483   \n",
       "3  0.798863  0.787328  0.814917  ...  0.510812  0.518949  0.595878  0.733483   \n",
       "4  0.798863  0.787328  0.814917  ...  0.510812  0.518949  0.595878  0.733483   \n",
       "5  0.798863  0.787328  0.814917  ...  0.510812  0.518949  0.595878  0.733483   \n",
       "\n",
       "     corr22    corr23    corr24   logDiff       log  normalLogDiff  \n",
       "1  0.746124  0.759237  0.768665  0.000000  3.806662       0.000000  \n",
       "2  0.746124  0.759237  0.768665  0.125163  3.931826       0.052939  \n",
       "3  0.746124  0.759237  0.768665  0.038466  3.970292       0.016270  \n",
       "4  0.746124  0.759237  0.768665 -0.163629  3.806662      -0.069209  \n",
       "5  0.746124  0.759237  0.768665  0.000000  3.806662       0.000000  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"60min_featureEngineer.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfStates = 255\n",
    "cuTrans = processData.markovianTransitionMatrixDegree1(data, numberOfStates, \"CU\")\n",
    "normalizedCuTrans = processData.normalizingTransMatrix(cuTrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparingMatrixForLumping(transitionMatrix):\n",
    "    reload(oldLumping)\n",
    "    percentageMatrix_list = bandwidthPercentage(transitionMatrix)\n",
    "    zero_cols_rows = []\n",
    "    #*************removing zeros from columns and rows (matrix reduction) ****************\n",
    "    for i in range(len(transitionMatrix)):\n",
    "        if (np.sum(transitionMatrix[i]) == 0) and (np.sum(transitionMatrix[:,i]) == 0):\n",
    "            zero_cols_rows.append(i)\n",
    "\n",
    "\n",
    "    irreducible_matrix = transitionMatrix.copy()\n",
    "    for i in range(len(zero_cols_rows) - 1, -1, -1):\n",
    "        irreducible_matrix = np.delete(irreducible_matrix, zero_cols_rows[i], axis = 0)\n",
    "        irreducible_matrix = np.delete(irreducible_matrix, zero_cols_rows[i], axis = 1)\n",
    "        percentageMatrix_list[zero_cols_rows[i]][2] = True\n",
    "\n",
    "\n",
    "    for i in range(len(percentageMatrix_list) - 1, 0, -1):\n",
    "        if (percentageMatrix_list[i][2] == True) and (percentageMatrix_list[i - 1][2] == True):\n",
    "            percentageMatrix_list[i - 1][0].extend(percentageMatrix_list[i][0])\n",
    "            percentageMatrix_list[i - 1][1] = percentageMatrix_list[i][1]\n",
    "            del percentageMatrix_list[i]\n",
    "\n",
    "    for i in range(len(irreducible_matrix)):\n",
    "        if np.sum(irreducible_matrix[i], dtype = np.float32) != 1.0:\n",
    "            print(np.sum(irreducible_matrix[i], dtype = np.float32))\n",
    "\n",
    "    return percentageMatrix_list, irreducible_matrix\n",
    "\n",
    "def bandwidthPercentage(vectorMatrix):\n",
    "    percentageIncreament = (100 / vectorMatrix.shape[0])\n",
    "    percentageMatrix = []\n",
    "    maxPercentage = 0\n",
    "    for j in range(vectorMatrix.shape[0]):\n",
    "        maxPercentage += percentageIncreament\n",
    "        percentageMatrix.append([[j], maxPercentage, False])\n",
    "\n",
    "    return percentageMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lumping_traditional' from '/home/sepehr/thesis/APDataML/lumping_traditional.py'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(oldLumping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 255, 255)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizedCuTrans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "we have these many sectors to check:  295382\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  35480\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "we have these many sectors to check:  75550\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  18336\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  11082\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "we have these many sectors to check:  5766\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  30657\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "we have these many sectors to check:  224326\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.9999999\n",
      "we have these many sectors to check:  308438\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  337462\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "1.0000001\n",
      "0.99999994\n",
      "we have these many sectors to check:  366134\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  366134\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "we have these many sectors to check:  366134\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "we have these many sectors to check:  366134\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "we have these many sectors to check:  366134\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  366134\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.9999999\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  366134\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  366134\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  366134\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.9999999\n",
      "0.99999994\n",
      "we have these many sectors to check:  366134\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "we have these many sectors to check:  310688\n",
      "0.9999999\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  156608\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.9999999\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  61442\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "we have these many sectors to check:  74856\n"
     ]
    }
   ],
   "source": [
    "for i in range((max(data[\"timeIndex\"]) + 1)):\n",
    "    percentageMatrix_list, irreducible_matrix = preparingMatrixForLumping(normalizedCuTrans[i])\n",
    "    result = oldLumping.lumping(irreducible_matrix, percentageMatrix_list, False)\n",
    "    nameResult = \"/home/sepehr/thesis/APDataML/pickles/5normal_25-10_lumping_60min_result_\" + str(i) + \".pickle\"\n",
    "    with open(nameResult, 'wb') as handle:\n",
    "        pickle.dump(result, handle)\n",
    "    namePercent = \"/home/sepehr/thesis/APDataML/pickles/5normal_25-10_lumping_60min_percentage_\" + str(i) + \".pickle\"\n",
    "    with open(namePercent, 'wb') as handle:\n",
    "        pickle.dump(percentageMatrix_list, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "arrayOfLumpes = []\n",
    "indexesOfCandidates = [[] for i in range((max(data[\"timeIndex\"]) + 1))]\n",
    "for timeIndex in range((max(data[\"timeIndex\"]) + 1)):\n",
    "    print(timeIndex)\n",
    "    name = \"/home/sepehr/thesis/APDataML/pickles/5normal_25-10_lumping_60min_result_\" + str(timeIndex) + \".pickle\"\n",
    "    with open(name, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "    \n",
    "    if len(b) > 0:\n",
    "        minDegree = np.inf        \n",
    "        for i in range(len(b)):\n",
    "            if b[i][0] < minDegree:\n",
    "                minDegree = b[i][0]\n",
    "\n",
    "        minError = np.inf\n",
    "        for i in range(len(b)):\n",
    "            if b[i][0] == minDegree and b[i][1] < minError:\n",
    "                minError = b[i][1]\n",
    "\n",
    "        for i in range(len(b)):\n",
    "            if b[i][0] == minDegree and b[i][1] == minError:\n",
    "                indexesOfCandidates[timeIndex].append(b[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"/home/sepehr/thesis/APDataML/pickles/5normal_25-10_lumping_60min.pickle\"\n",
    "with open(name, 'wb') as handle:\n",
    "    pickle.dump(indexesOfCandidates, handle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lumping_traditional' from '/home/sepehr/thesis/APDataML/lumping_traditional.py'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(oldLumping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "we have these many sectors to check:  9380\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  1888\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "we have these many sectors to check:  3031\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  1347\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  338\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "we have these many sectors to check:  24\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  4014\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "we have these many sectors to check:  10885\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.9999999\n",
      "we have these many sectors to check:  12500\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  12838\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "1.0000001\n",
      "0.99999994\n",
      "we have these many sectors to check:  13048\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  13048\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "we have these many sectors to check:  13048\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.9999999\n",
      "we have these many sectors to check:  13048\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "we have these many sectors to check:  13048\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "we have these many sectors to check:  13048\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.9999999\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  13048\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  13048\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  13048\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.9999999\n",
      "0.99999994\n",
      "we have these many sectors to check:  13048\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.9999999\n",
      "0.99999994\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "we have these many sectors to check:  12077\n",
      "0.9999999\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  7030\n",
      "1.0000001\n",
      "1.0000001\n",
      "0.99999994\n",
      "0.9999999\n",
      "1.0000001\n",
      "0.99999994\n",
      "1.0000001\n",
      "we have these many sectors to check:  4673\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "0.99999994\n",
      "1.0000001\n",
      "0.99999994\n",
      "we have these many sectors to check:  1596\n"
     ]
    }
   ],
   "source": [
    "for i in range((max(data[\"timeIndex\"]) + 1)):\n",
    "    percentageMatrix_list, irreducible_matrix = preparingMatrixForLumping(normalizedCuTrans[i])\n",
    "    result = oldLumping.lumping(irreducible_matrix, percentageMatrix_list, False)\n",
    "    nameResult = \"/home/sepehr/thesis/APDataML/pickles/4normal_25-10_lumping_60min_result_\" + str(i) + \".pickle\"\n",
    "    with open(nameResult, 'wb') as handle:\n",
    "        pickle.dump(result, handle)\n",
    "    namePercent = \"/home/sepehr/thesis/APDataML/pickles/4normal_25-10_lumping_60min_percentage_\" + str(i) + \".pickle\"\n",
    "    with open(namePercent, 'wb') as handle:\n",
    "        pickle.dump(percentageMatrix_list, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "arrayOfLumpes = []\n",
    "indexesOfCandidates = [[] for i in range((max(data[\"timeIndex\"]) + 1))]\n",
    "for timeIndex in range((max(data[\"timeIndex\"]) + 1)):\n",
    "    print(timeIndex)\n",
    "    name = \"/home/sepehr/thesis/APDataML/pickles/4normal_25-10_lumping_60min_result_\" + str(timeIndex) + \".pickle\"\n",
    "    with open(name, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "    \n",
    "    if len(b) > 0:\n",
    "        minDegree = np.inf        \n",
    "        for i in range(len(b)):\n",
    "            if b[i][0] < minDegree:\n",
    "                minDegree = b[i][0]\n",
    "\n",
    "        minError = np.inf\n",
    "        for i in range(len(b)):\n",
    "            if b[i][0] == minDegree and b[i][1] < minError:\n",
    "                minError = b[i][1]\n",
    "\n",
    "        for i in range(len(b)):\n",
    "            if b[i][0] == minDegree and b[i][1] == minError:\n",
    "                indexesOfCandidates[timeIndex].append(b[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"/home/sepehr/thesis/APDataML/pickles/4normal_25-10_lumping_60min.pickle\"\n",
    "with open(name, 'wb') as handle:\n",
    "    pickle.dump(indexesOfCandidates, handle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifying(CU, boundaries):\n",
    "    occupiedBandwidth = (CU / 255) * 100\n",
    "    for i in range(len(boundaries)):\n",
    "        if occupiedBandwidth <= boundaries[i]:\n",
    "            return i\n",
    "        \n",
    "def dataPreparation(data, timeIndexes, minuteSplit, boundaries):\n",
    "    from sklearn.utils import shuffle\n",
    "    warnings.filterwarnings('always')\n",
    "    reg = \"l2\"\n",
    "    solvers = \"lbfgs\"\n",
    "    clf = LogisticRegression(penalty = reg, max_iter = 100000, random_state = 0,\n",
    "                             solver = solvers , multi_class = 'multinomial')\n",
    "    accuracyValue = 0\n",
    "    numOfElements = 0\n",
    "    f1scoreValue = 0\n",
    "    precisionValue = 0\n",
    "    recallValue = 0\n",
    "    prevRowTrain = np.inf\n",
    "    prevCU = np.inf\n",
    "\n",
    "    sampleIntervals = 6 #seconds\n",
    "    minuteSplit = 30 #minutes\n",
    "    numOfSamples = minuteSplit * 60 / sampleIntervals\n",
    "    # numberOfDays = len(numOfDays)\n",
    "    days = np.zeros(7)\n",
    "    numOfThirtyMinsPerDay = np.zeros(int((24 * 60) / minuteSplit)) #in this case 48\n",
    "#     which6SecondsPerPeriod = np.zeros(int(minuteSplit * 60 / sampleIntervals)) #in this case 300\n",
    "    prevRowTrain = np.inf\n",
    "    prevCU = np.inf\n",
    "\n",
    "    XArraysForLearning = []\n",
    "    YArraysForLearning = []\n",
    "    XArraysForTesting = []\n",
    "    YArraysForTesting = []\n",
    "\n",
    "    x = timeIndexes\n",
    "    wholeDataFrame = data.loc[(data[\"timeIndex\"] == x)].copy()\n",
    "    \n",
    "    wholeDataFrame[\"cuClass\"] = wholeDataFrame[\"CU\"].apply(lambda x: classifying(x, boundaries))\n",
    "\n",
    "    \n",
    "\n",
    "    stackCounter = 0\n",
    "    prevCU = 0\n",
    "    prev2CU = 0\n",
    "    prev3CU = 0\n",
    "    prev4CU = 0\n",
    "    prev5CU = 0\n",
    "    print(\"start training set generation\")\n",
    "    #number of features are: prevCU + 48 correlations + 1 logDiff\n",
    "    numberOfFeatures = len(boundaries) + 24 + 1 \n",
    "    \n",
    "    XArraysForLearning = np.zeros(shape=(len(wholeDataFrame), numberOfFeatures))\n",
    "    YArraysForLearning = np.zeros(shape=(len(wholeDataFrame), len(boundaries)))\n",
    "#     print(len(trainingDataFrame))\n",
    "    counter = 0\n",
    "    pandasIndexCounter = 0\n",
    "    for index, row in wholeDataFrame.iterrows():\n",
    "        XArraysForLearning[pandasIndexCounter, prevCU] = 1\n",
    "        for corrs in range(24):\n",
    "            XArraysForLearning[pandasIndexCounter, len(boundaries) + corrs] = row[\"corr\" + str(corrs + 1)]\n",
    "\n",
    "        XArraysForLearning[pandasIndexCounter, len(boundaries) + 24] = row[\"normalLogDiff\"]\n",
    "        YArraysForLearning[pandasIndexCounter, row[\"cuClass\"]] = 1\n",
    "#         print(XArraysForLearning[pandasIndexCounter])\n",
    "\n",
    "        which6SecondsPerPeriod = 0\n",
    "    \n",
    "        prevCU = row[\"cuClass\"]\n",
    "        pandasIndexCounter += 1\n",
    "\n",
    "    XArraysForLearning, YArraysForLearning = shuffle(XArraysForLearning, YArraysForLearning, random_state=0)\n",
    "    XArraysForTraining = XArraysForLearning[:int(0.8*len(XArraysForLearning))]\n",
    "    YArraysForTraining = YArraysForLearning[:int(0.8*len(YArraysForLearning))]\n",
    "    XArraysForTesting = XArraysForLearning[int(0.8*len(XArraysForLearning)):]\n",
    "    YArraysForTesting = YArraysForLearning[int(0.8*len(YArraysForLearning)):]\n",
    "    print(XArraysForTraining.shape[0])\n",
    "    print(XArraysForTesting.shape[0])\n",
    "\n",
    "\n",
    "    return XArraysForTraining, YArraysForTraining, XArraysForTesting, YArraysForTesting, boundaries\n",
    "\n",
    "def tensorFlowLossFunction(\n",
    "    lossFuncBool, XArraysForLearning, YArraysForLearning, XArraysForTesting, YArraysForTesting, boundaries):\n",
    "    \n",
    "    batch_size = 64\n",
    "    learning_rate = 0.01\n",
    "    beta = 0.1\n",
    "    numOfEpochs = 5000\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        x = tf.placeholder(tf.float32, shape = (batch_size, XArraysForLearning.shape[1]))\n",
    "        y_ = tf.placeholder(tf.float32, shape = (batch_size, YArraysForLearning.shape[1]))\n",
    "#         print(weights.dtype)\n",
    "#         print(weights.shape)\n",
    "#         print(XArraysForLearning.shape[1], YArraysForLearning.shape[1])\n",
    "#         multiDistrib = np.vstack((mult, mult))\n",
    "#         for i in range(batch_size - 2):\n",
    "#             multiDistrib = np.vstack((multiDistrib, mult))\n",
    "        W = tf.Variable(tf.truncated_normal([XArraysForLearning.shape[1], YArraysForLearning.shape[1]], seed = 0), name=\"weights\", dtype=tf.float32)\n",
    "        b = tf.Variable(tf.truncated_normal([YArraysForLearning.shape[1]], seed = 0), dtype=tf.float32)\n",
    "\n",
    "        tf_test_dataset64 = tf.constant(XArraysForTesting)\n",
    "        tf_test_dataset = tf.cast(tf_test_dataset64, tf.float32)\n",
    "\n",
    "\n",
    "        beta = 0.05\n",
    "        logits = tf.matmul(x, W)\n",
    "        train_prediction = tf.nn.softmax(logits)\n",
    "        # train_prediction = tf.nn.softmax_cross_entropy_with_logits_v2(labels = y_, logits = logits)\n",
    "        test_prediction = tf.nn.softmax(tf.add(tf.matmul(tf_test_dataset, W),b))\n",
    "\n",
    "        # x = XArraysForLearning[0:(0 + batch_size), :]\n",
    "        # y_ = tf.Variable(YArraysForLearning[0:(0 + batch_size), :])\n",
    "\n",
    "        # loss = assymetricLossFunction(train_prediction, y_, boundaries)\n",
    "        # loss = assymetricLossFunction(train_prediction, y_, boundaries)\n",
    "        \n",
    "        if lossFuncBool == 0:\n",
    "            loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = y_)\n",
    "        \n",
    "        elif lossFuncBool == 1:\n",
    "            loss = assymetricLossFunction(train_prediction, y_, boundaries)\n",
    "#         dist = tfp.distributions.Multinomial(total_count=1, logits=logits)\n",
    "#         loss = loss - (dist.log_prob(mult))\n",
    "        # regularizer = tf.nn.l2_loss(W)\n",
    "        # loss = tf.reduce_mean(loss + beta * regularizer)\n",
    "        # loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits = train_prediction, labels = y_)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "        prevAcc = 0\n",
    "        prevLoss = np.inf\n",
    "\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        initializer = tf.contrib.layers.xavier_initializer()\n",
    "        tf.set_random_seed(0)\n",
    "        W = tf.Variable(initializer([XArraysForLearning.shape[1], YArraysForLearning.shape[1]]))\n",
    "        b = tf.Variable(initializer([YArraysForLearning.shape[1]]))       \n",
    "        tf.global_variables_initializer().run()\n",
    "#         print(W.eval())\n",
    "        \n",
    "        print(\"Initialized\")\n",
    "\n",
    "        numberOfBatchIteration = int(XArraysForLearning.shape[0] / batch_size)\n",
    "        restOfData = XArraysForLearning.shape[0] % batch_size\n",
    "        if restOfData != 0:\n",
    "            numberOfBatchIteration += 1\n",
    "\n",
    "        accuracy_result = 0\n",
    "        accuracy_earlyStop = 0\n",
    "        earlyStoppingCounter = 0\n",
    "        \n",
    "        for epoch in range(numOfEpochs):\n",
    "            accuracyValue = 0\n",
    "            lossValue = 0\n",
    "            totalBatch = 0\n",
    "            i = 0\n",
    "            randomize = np.arange(XArraysForLearning.shape[0])\n",
    "            random.Random(epoch).shuffle(randomize)\n",
    "            XArraysForLearning = XArraysForLearning[randomize]\n",
    "            YArraysForLearning = YArraysForLearning[randomize]\n",
    "\n",
    "            for iteration in range(numberOfBatchIteration):\n",
    "                if (iteration == numberOfBatchIteration - 1) and restOfData != 0:\n",
    "                    break\n",
    "                    batch_data = XArraysForLearning[i:, :]\n",
    "                    batch_labels = YArraysForLearning[i:, :]\n",
    "\n",
    "                else:\n",
    "                    batch_data = XArraysForLearning[i:(i + batch_size), :]\n",
    "                    batch_labels = YArraysForLearning[i:(i + batch_size), :]\n",
    "\n",
    "                    i += batch_size\n",
    "\n",
    "\n",
    "                feed_dict = {x : batch_data, y_ : batch_labels}\n",
    "                _, predictions, l = session.run([optimizer, train_prediction, loss], feed_dict=feed_dict)\n",
    "\n",
    "#                 print(l)\n",
    "                lossValue *= (iteration)\n",
    "                lossValue += (np.sum(l))\n",
    "                lossValue /= (iteration + 1)\n",
    "                totalBatch += batch_size\n",
    "                # print(accuracy(batch_data, batch_labels))\n",
    "                \n",
    "                accuracyValue += accuracy(predictions, batch_labels) * batch_size\n",
    "\n",
    "\n",
    "            totalAccuracy = accuracyValue/totalBatch\n",
    "#             print(session.run(W))\n",
    "#             test_result = test_prediction.eval()\n",
    "            if epoch % 20 == 0:\n",
    "                print(\"epoch \", epoch, totalAccuracy, lossValue)\n",
    "                \n",
    "            if lossValue > prevLoss and earlyStoppingCounter == 50:\n",
    "                break\n",
    "\n",
    "            elif lossValue > prevLoss:\n",
    "                earlyStoppingCounter += 1\n",
    "\n",
    "            elif lossValue <= prevLoss:\n",
    "                prevLoss = lossValue\n",
    "                earlyStoppingCounter = 0\n",
    "#             print(lossValue, prevLoss)\n",
    "                \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "        # print(session.run(W))\n",
    "        predictionResult = test_prediction.eval()\n",
    "        accResult = accuracy(predictionResult , YArraysForTesting)\n",
    "        penaltyValue = assymetricPredictionScore(predictionResult, YArraysForTesting, boundaries)\n",
    "#         print(W.eval())\n",
    "        accuracy_result = accResult\n",
    "            \n",
    "        correctLableIndex = np.argmax(YArraysForTesting, 1)\n",
    "        predictionIndex = np.argmax(predictionResult, 1)\n",
    "        \n",
    "        precision = precision_score(correctLableIndex, predictionIndex, average='weighted')\n",
    "        recall = recall_score(correctLableIndex, predictionIndex, average='weighted')\n",
    "        f1Score = f1_score(correctLableIndex, predictionIndex, average='weighted')            \n",
    "        \n",
    "        return accuracy_result, penaltyValue, precision, recall, f1Score\n",
    "\n",
    "            \n",
    "    \n",
    "def assymetricPredictionScore(predictedLables, trueLables, boundaries):\n",
    "    xAxisPoints = np.linspace(rayleigh.ppf(0.01), rayleigh.ppf(0.99), 338)\n",
    "    #number of overal datapoints must stay the same all the time\n",
    "    maxState = 338\n",
    "\n",
    "    inverseDistrib = max(rayleigh.pdf(xAxisPoints)) - rayleigh.pdf(xAxisPoints)\n",
    "    minState = np.argmin(inverseDistrib)\n",
    "\n",
    "    underUtilizedSum = 0\n",
    "    overUtilizedSum = 0\n",
    "    numberOfUnderUtilizedStates = minState - 0\n",
    "    numberOfOverUtilizedStates = maxState - minState\n",
    "\n",
    "    xAxisPoints -= xAxisPoints[np.argmin(inverseDistrib)]\n",
    "\n",
    "    underUtilVal = numberOfUnderUtilizedStates / 100\n",
    "    overUtilVal = numberOfOverUtilizedStates / 100\n",
    "\n",
    "    correctLableIndex = np.argmax(trueLables, 1)\n",
    "    predictionIndex = np.argmax(predictedLables, 1)\n",
    "\n",
    "    diffPercentage = np.zeros(shape = (predictedLables.shape))\n",
    "\n",
    "    penalties = np.zeros(shape = (predictedLables.shape))\n",
    "\n",
    "    for index in range(predictedLables.shape[0]):\n",
    "        diffPercentage[index] = boundaries[correctLableIndex[index]] - boundaries[:]\n",
    "\n",
    "\n",
    "    for i in range(diffPercentage.shape[0]):\n",
    "        for j in range(diffPercentage.shape[1]):\n",
    "            if diffPercentage[i][j] > 0:\n",
    "                penalties[i][j] = inverseDistrib[minState + math.floor\n",
    "                                                  (diffPercentage[i][j] * overUtilVal)]\n",
    "            else:\n",
    "                penalties[i][j] = inverseDistrib[minState + math.floor\n",
    "                                                  (diffPercentage[i][j] * underUtilVal)]\n",
    "\n",
    "    sumOfPenalty = 0\n",
    "    for i in range(predictionIndex.shape[0]):\n",
    "        sumOfPenalty += penalties[i][predictionIndex[i]]\n",
    "\n",
    "    return sumOfPenalty\n",
    "    \n",
    "    \n",
    "def accuracy(predictedLables, trueLables):\n",
    "    import sys\n",
    "    np.set_printoptions(threshold=sys.maxsize)\n",
    "    correctLableIndex = np.argmax(trueLables, 1)\n",
    "    predictionIndex = np.argmax(predictedLables, 1)\n",
    "    errors = [0 for i in range(trueLables.shape[1])]\n",
    "    corrects = [0 for i in range(trueLables.shape[1])]\n",
    "    for i in range(len(correctLableIndex)):\n",
    "        if correctLableIndex[i] != predictionIndex[i]:\n",
    "            errors[correctLableIndex[i]] += 1\n",
    "            corrects[predictionIndex[i]] += 1\n",
    "\n",
    "    acc = np.float64(np.sum(correctLableIndex == predictionIndex)/predictedLables.shape[0])\n",
    "    return acc\n",
    "    \n",
    "    \n",
    "def assymetricLossFunction(prediction, correctLable, boundaries):\n",
    "    xAxisPoints = np.linspace(rayleigh.ppf(0.01), rayleigh.ppf(0.99), 338)\n",
    "    #number of overal datapoints must stay the same all the time\n",
    "    maxState = 338\n",
    "    inverseDistrib = max(rayleigh.pdf(xAxisPoints)) - rayleigh.pdf(xAxisPoints)\n",
    "    inverseDistrib = tf.constant(inverseDistrib)\n",
    "    xAxisPoints -= xAxisPoints[np.argmin(inverseDistrib)]\n",
    "    minState = np.argmin(inverseDistrib)\n",
    "    numberOfOverUtilizedStates = maxState - minState\n",
    "    numberOfUnderUtilizedStates = minState\n",
    "    minState = tf.constant(minState, tf.float32)\n",
    "    numberOfOverUtilizedStates = tf.constant(numberOfOverUtilizedStates, tf.float32)\n",
    "    numberOfUnderUtilizedStates = tf.constant(numberOfUnderUtilizedStates, tf.float32)\n",
    "\n",
    "    underUtilVal = numberOfUnderUtilizedStates / 100\n",
    "    overUtilVal = numberOfOverUtilizedStates / 100\n",
    "\n",
    "\n",
    "    boundaries = tf.constant(boundaries, tf.float32)\n",
    "    correctLableIndex = tf.argmax(correctLable, 1)\n",
    "\n",
    "    diffPercentage = []\n",
    "    for index in range(correctLableIndex.shape[0]):\n",
    "        diffPercentage.append(boundaries[correctLableIndex[index]] - boundaries[:])\n",
    "\n",
    "    diffPercentage = tf.stack(diffPercentage)\n",
    "\n",
    "    penalties = []\n",
    "\n",
    "    counter = 0\n",
    "    for i in range(diffPercentage.shape[0]):\n",
    "        for j in range(diffPercentage.shape[1]):\n",
    "            counter += 1\n",
    "\n",
    "            penalties.append(tf.cond(\n",
    "                    tf.greater(diffPercentage[i][j], 0),\n",
    "                    lambda: inverseDistrib[tf.dtypes.cast(minState + tf.math.floor\n",
    "                                                                   (tf.math.scalar_mul(diffPercentage[i][j],\n",
    "                                                                                       overUtilVal)), tf.int32)],\n",
    "                    lambda: inverseDistrib[tf.dtypes.cast(minState + tf.math.floor\n",
    "                                                                   (tf.math.scalar_mul\n",
    "                                                                    (diffPercentage[i][j], underUtilVal))\n",
    "                                                                   , tf.int32)]\n",
    "                    ))\n",
    "\n",
    "    penalties = tf.stack(penalties)\n",
    "    penalties = tf.dtypes.cast(penalties, tf.float32)\n",
    "    penalties = tf.reshape(penalties, diffPercentage.shape)\n",
    "    penalties = penalties / tf.norm(penalties)\n",
    "\n",
    "    # weights = tf.reduce_sum(penalties * (1-prediction), axis=1)\n",
    "    weights = (1 - penalties) * prediction\n",
    "    weights = weights / tf.norm(weights)\n",
    "    # print(correctLable)\n",
    "    # print(prediction)\n",
    "    # print(penalties)\n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels = correctLable, logits = weights)\n",
    "    # weighted_losses = tf.nn.softmax_cross_entropy_with_logits_v2(labels = penalties, logits = prediction)\n",
    "    # loss = tf.reduce_sum(weighted_losses)\n",
    "    # loss = tf.reduce_sum(penalties * prediction)\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cuTran_cpy = normalizedCuTrans_60min.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"/home/sepehr/thesis/APDataML/pickles/5normal_25-10_lumping_60min.pickle\"\n",
    "with open(name, 'rb') as handle:\n",
    "    normalLumping = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentageArray = []\n",
    "for i in range(len(normalLumping)):\n",
    "    name = \"/home/sepehr/thesis/APDataML/pickles/5normal_25-10_lumping_60min_percentage_\" + str(i) + \".pickle\"\n",
    "    with open(name, 'rb') as handle:\n",
    "        percentageArray.append(pickle.load(handle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracyResult = [np.inf for i in range(len(normalLumping))]\n",
    "penaltyResult = [np.inf for i in range(len(normalLumping))]\n",
    "precisionResult = [np.inf for i in range(len(normalLumping))]\n",
    "recallResult = [np.inf for i in range(len(normalLumping))]\n",
    "f1ScoreResult = [np.inf for i in range(len(normalLumping))]\n",
    "boundariesResult = [np.inf for i in range(len(normalLumping))]\n",
    "lumpAproxResult = [np.inf for i in range(len(normalLumping))]\n",
    "lumpErrorResult = [np.inf for i in range(len(normalLumping))]\n",
    "\n",
    "\n",
    "testDataFrame = {\"accuracy\": accuracyResult, \"penalty\": penaltyResult, \"precision\": precisionResult, \n",
    "                 \"recall\": recallResult, \"f1Score\": f1ScoreResult, \"boundaries\": boundariesResult, \n",
    "                 \"lumpAprox\": lumpAproxResult, \"lumpError\": lumpErrorResult}\n",
    "\n",
    "result_25_10_6class_60min_DataFrameNoPenalty = pd.DataFrame(testDataFrame)\n",
    "result_25_10_6class_60min_DataFrameNoPenalty = result_25_10_6class_60min_DataFrameNoPenalty.astype('object')\n",
    "\n",
    "result_25_10_6class_60min_DataFrameNoPenalty = pd.DataFrame(testDataFrame)\n",
    "result_25_10_6class_60min_DataFrameNoPenalty = result_25_10_6class_60min_DataFrameNoPenalty.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[ 10.19607843  32.15686275  51.37254902  71.37254902  82.35294118\n",
      " 100.        ]\n",
      "start training set generation\n",
      "37896\n",
      "9475\n",
      "starting tensor\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Initialized\n",
      "epoch  0 0.8565772804054054 24.252476715558288\n",
      "epoch  20 0.9329866976351351 10.407262885489978\n",
      "epoch  40 0.9341744087837838 10.166129386102831\n",
      "epoch  60 0.9347550675675675 10.072752795912123\n",
      "epoch  80 0.9354676942567568 9.971936273413734\n",
      "epoch  100 0.9348078547297297 9.954424748146858\n",
      "epoch  120 0.9358372043918919 9.933925915408777\n",
      "epoch  140 0.9352565456081081 9.865325343367212\n",
      "epoch  160 0.9359163851351351 9.859318934582383\n",
      "epoch  180 0.9358372043918919 9.861171522656004\n",
      "epoch  200 0.9366817989864865 9.817926467673203\n",
      "epoch  220 0.9359955658783784 9.807164056881062\n",
      "epoch  240 0.9357052364864865 9.784539922266395\n",
      "epoch  260 0.9361539273648649 9.767627694316804\n",
      "epoch  280 0.9366554054054054 9.756060077934652\n",
      "epoch  300 0.9356260557432432 9.727663671648195\n",
      "epoch  320 0.9357052364864865 9.719883062146806\n",
      "epoch  340 0.9361803209459459 9.697100599271216\n",
      "epoch  360 0.9356788429054054 9.723765248785151\n",
      "epoch  380 0.9362331081081081 9.731212131477701\n",
      "epoch  400 0.935230152027027 9.693066102024677\n",
      "epoch  420 0.9370513091216216 9.669587362054239\n",
      "epoch  440 0.9368929476351351 9.671050081784669\n",
      "epoch  460 0.9360483530405406 9.662028061377022\n",
      "epoch  480 0.9356788429054054 9.730054010007835\n",
      "epoch  500 0.9364178631756757 9.701500554543898\n",
      "epoch  520 0.9366026182432432 9.648130293230754\n",
      "epoch  540 0.9359955658783784 9.701401485381894\n",
      "epoch  560 0.9363914695945946 9.67120590564367\n",
      "epoch  580 0.9362331081081081 9.685915180960217\n",
      "epoch  600 0.9359163851351351 9.656466360027725\n",
      "epoch  620 0.9367081925675675 9.627473863395489\n",
      "epoch  640 0.9357580236486487 9.64979656040669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[ 10.19607843  34.11764706  48.23529412  59.21568627  76.07843137\n",
      " 100.        ]\n",
      "start training set generation\n",
      "38177\n",
      "9545\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8595847315436241 23.426615580616385\n",
      "epoch  20 0.9325188758389261 10.676719001875627\n",
      "epoch  40 0.9321256291946308 10.4066111009393\n",
      "epoch  60 0.9337772651006712 10.274520583200765\n",
      "epoch  80 0.933567533557047 10.155270239250758\n",
      "epoch  100 0.9345637583892618 10.12879359722137\n",
      "epoch  120 0.9355599832214765 10.071399506306497\n",
      "epoch  140 0.9357172818791947 10.017849590954361\n",
      "epoch  160 0.934878355704698 9.968959489524774\n",
      "epoch  180 0.9352716023489933 9.950518088052737\n",
      "epoch  200 0.9361629614093959 9.915758630973388\n",
      "epoch  220 0.936215394295302 9.868592869115357\n",
      "epoch  240 0.9366348573825504 9.845501659700545\n",
      "epoch  260 0.9358745805369127 9.809767575071968\n",
      "epoch  280 0.9357434983221476 9.807983492844842\n",
      "epoch  300 0.936189177852349 9.789443542093238\n",
      "epoch  320 0.9359007969798657 9.799934403008272\n",
      "epoch  340 0.9360318791946308 9.768590691105627\n",
      "epoch  360 0.9359532298657718 9.780763494488376\n",
      "epoch  380 0.9366086409395973 9.711837285317031\n",
      "epoch  400 0.9360318791946308 9.708415403862125\n",
      "epoch  420 0.9368183724832215 9.7001214839468\n",
      "epoch  440 0.9360318791946308 9.738785048859233\n",
      "epoch  460 0.9363989093959731 9.677232384281673\n",
      "epoch  480 0.9361629614093959 9.673811080071738\n",
      "epoch  500 0.9369494546979866 9.643584927256484\n",
      "epoch  520 0.9371067533557047 9.65877177451281\n",
      "epoch  540 0.9370543204697986 9.66281331905582\n",
      "epoch  560 0.9365037751677853 9.621470356547585\n",
      "epoch  580 0.9367659395973155 9.625913396977737\n",
      "epoch  600 0.9372116191275168 9.620706871851976\n",
      "epoch  620 0.9368183724832215 9.65365039782237\n",
      "epoch  640 0.9372116191275168 9.608228553861576\n",
      "epoch  660 0.9366086409395973 9.608655358320913\n",
      "epoch  680 0.937578649328859 9.559266608433441\n",
      "epoch  700 0.9367921560402684 9.612483516635503\n",
      "epoch  720 0.9375524328859061 9.634001191430462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[ 24.31372549  42.35294118  54.11764706  64.31372549  78.03921569\n",
      " 100.        ]\n",
      "start training set generation\n",
      "37746\n",
      "9437\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.9476867572156197 11.211383359136722\n",
      "epoch  20 0.9628873089983022 6.111602317699958\n",
      "epoch  40 0.9633648132427843 5.9831520635729545\n",
      "epoch  60 0.9639749575551783 6.027518720092513\n",
      "epoch  80 0.9627811969439728 5.973233169630954\n",
      "epoch  100 0.9636566213921901 5.941916274599388\n",
      "epoch  120 0.9635239813242784 5.934606357624656\n",
      "epoch  140 0.9630730050933786 5.916916393059828\n",
      "epoch  160 0.9637892614601019 5.918616447667312\n",
      "epoch  180 0.9634443972835314 5.862703787855464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[ 23.1372549   34.11764706  48.23529412  61.17647059  84.31372549\n",
      " 100.        ]\n",
      "start training set generation\n",
      "37448\n",
      "9363\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.9305288461538461 14.13561233985118\n",
      "epoch  20 0.9540331196581197 7.542882461221809\n",
      "epoch  40 0.9536057692307692 7.434407356661609\n",
      "epoch  60 0.9542200854700855 7.402943584654066\n",
      "epoch  80 0.9543269230769231 7.356353712897016\n",
      "epoch  100 0.9545673076923077 7.382375198704566\n",
      "epoch  120 0.9541132478632479 7.323275300987765\n",
      "epoch  140 0.9544871794871795 7.316185671651465\n",
      "epoch  160 0.9545940170940171 7.300231438212925\n",
      "epoch  180 0.9545673076923077 7.342681295749468\n",
      "epoch  200 0.9547275641025641 7.298032712732625\n",
      "epoch  220 0.9544337606837607 7.28434280992573\n",
      "epoch  240 0.9545138888888889 7.3029532155420025\n",
      "epoch  260 0.9543269230769231 7.269282776575822\n",
      "epoch  280 0.9544070512820513 7.310357893430271\n",
      "epoch  300 0.9548611111111112 7.262960309350593\n",
      "4\n",
      "[ 24.31372549  35.29411765  51.37254902  62.35294118  87.05882353\n",
      " 100.        ]\n",
      "start training set generation\n",
      "38121\n",
      "9531\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.9426995798319328 11.735307962153138\n",
      "epoch  20 0.959375 6.682477170729837\n",
      "epoch  40 0.9592699579831933 6.596384451769985\n",
      "epoch  60 0.9592699579831933 6.592026945322503\n",
      "epoch  80 0.9597163865546219 6.515485764651741\n",
      "epoch  100 0.9598214285714286 6.553849868614134\n",
      "epoch  120 0.9594275210084033 6.546276582589666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[ 10.19607843  34.11764706  51.37254902  70.19607843  88.23529412\n",
      " 100.        ]\n",
      "start training set generation\n",
      "37322\n",
      "9331\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8666112778730704 22.38165411123076\n",
      "epoch  20 0.9382772298456261 9.963500345959666\n",
      "epoch  40 0.9389740566037735 9.791116300618873\n",
      "epoch  60 0.9380628216123499 9.731552085990971\n",
      "epoch  80 0.9392956689536878 9.616585715557246\n",
      "epoch  100 0.9388132504288165 9.604346439319034\n",
      "epoch  120 0.9397512864493996 9.557694314479019\n",
      "epoch  140 0.9410377358490566 9.52360269585768\n",
      "epoch  160 0.9407161234991424 9.505545955170495\n",
      "epoch  180 0.9413593481989708 9.47819095839767\n",
      "epoch  200 0.9408769296740995 9.451016116101373\n",
      "epoch  220 0.9397512864493996 9.431376213479405\n",
      "epoch  240 0.94085012864494 9.40583529848586\n",
      "epoch  260 0.9408769296740995 9.410802650615231\n",
      "epoch  280 0.94028730703259 9.391398456452434\n",
      "epoch  300 0.940957332761578 9.389344258537426\n",
      "epoch  320 0.940957332761578 9.378503001574591\n",
      "epoch  340 0.9405553173241853 9.368173622962328\n",
      "epoch  360 0.9404481132075472 9.367632208312136\n",
      "epoch  380 0.9408233276157805 9.374669578022248\n",
      "epoch  400 0.94085012864494 9.409725525366913\n",
      "epoch  420 0.9414933533447685 9.351890426966172\n",
      "epoch  440 0.94085012864494 9.334236526979993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning:\n",
      "\n",
      "Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[ 10.19607843  32.15686275  50.19607843  60.39215686  76.07843137\n",
      " 100.        ]\n",
      "start training set generation\n",
      "36891\n",
      "9223\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8625217013888888 23.27072941594654\n",
      "epoch  20 0.9369845920138888 10.229756588323246\n",
      "epoch  40 0.9376085069444444 9.993490440977943\n",
      "epoch  60 0.9375542534722222 9.910529797689788\n",
      "epoch  80 0.9382866753472222 9.869228030244507\n",
      "epoch  100 0.9376085069444444 9.832701798321466\n",
      "epoch  120 0.9382595486111112 9.762665220018881\n",
      "epoch  140 0.9386393229166666 9.711051821294753\n",
      "epoch  160 0.9388834635416666 9.719931843380145\n",
      "epoch  180 0.9387478298611112 9.68450922022263\n",
      "epoch  200 0.9389919704861112 9.656439356505878\n",
      "epoch  220 0.9385579427083334 9.672279569216897\n",
      "epoch  240 0.9382866753472222 9.644332674228478\n",
      "epoch  260 0.9392632378472222 9.632040054019956\n",
      "epoch  280 0.9379069010416666 9.66703984431095\n",
      "epoch  300 0.93896484375 9.637646878759064\n",
      "epoch  320 0.9385579427083334 9.624231559327914\n",
      "epoch  340 0.9384494357638888 9.587007252292501\n",
      "epoch  360 0.9386664496527778 9.591678768396381\n",
      "epoch  380 0.9389919704861112 9.569763804889392\n",
      "epoch  400 0.9382595486111112 9.568029969516733\n",
      "epoch  420 0.9386935763888888 9.55604643995563\n",
      "epoch  440 0.938232421875 9.581918194890026\n",
      "epoch  460 0.9391547309027778 9.537382847112083\n",
      "7\n",
      "[ 11.37254902  36.07843137  50.19607843  63.1372549   81.17647059\n",
      " 100.        ]\n",
      "start training set generation\n",
      "36717\n",
      "9180\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8517942844677138 27.946098450798814\n",
      "epoch  20 0.9138852530541012 13.475326644604536\n",
      "epoch  40 0.9140215968586387 13.19559040369164\n",
      "epoch  60 0.9141579406631762 13.089900246881488\n",
      "epoch  80 0.9147578534031413 13.009281931539268\n",
      "epoch  100 0.9165303228621291 12.930117803510361\n",
      "epoch  120 0.9165030541012217 12.941465011649939\n",
      "epoch  140 0.9166393979057592 12.842919797381393\n",
      "epoch  160 0.9163121727748691 12.8652619029839\n",
      "epoch  180 0.9160940226876091 12.807402556687334\n",
      "epoch  200 0.9163121727748691 12.842349686963813\n",
      "epoch  220 0.9171029668411868 12.848827211852683\n",
      "epoch  240 0.9166666666666666 12.837835766258033\n",
      "epoch  260 0.9165575916230366 12.83631175350769\n",
      "epoch  280 0.9165303228621291 12.783822293472955\n",
      "epoch  300 0.9175119982547993 12.803839968137096\n",
      "epoch  320 0.9155213787085514 12.830312951072974\n",
      "epoch  340 0.9164212478184991 12.762868590379888\n",
      "epoch  360 0.916148560209424 12.805099393684824\n",
      "epoch  380 0.9170484293193717 12.737725225418648\n",
      "epoch  400 0.9172120418848168 12.762126484466469\n",
      "epoch  420 0.9163667102966842 12.784405062127904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[ 13.33333333  37.25490196  60.39215686  78.03921569  88.23529412\n",
      " 100.        ]\n",
      "start training set generation\n",
      "37100\n",
      "9276\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8480677892918825 27.51591675022104\n",
      "epoch  20 0.9175032383419689 13.247096219005158\n",
      "epoch  40 0.9188795336787565 13.084595332697472\n",
      "epoch  60 0.918933506044905 13.052742826300376\n",
      "epoch  80 0.9190684369602763 13.084416175341563\n",
      "epoch  100 0.9192843264248705 12.958185181510677\n",
      "epoch  120 0.9193113126079447 12.96231655053318\n",
      "epoch  140 0.9196891191709845 12.966946030733702\n",
      "epoch  160 0.9199589810017271 12.903057397750171\n",
      "epoch  180 0.9203907599309153 12.96022107522928\n",
      "epoch  200 0.9204987046632125 12.923414732713985\n",
      "epoch  220 0.9206606217616581 12.881475597671479\n",
      "epoch  240 0.9203907599309153 12.8707084458109\n",
      "epoch  260 0.9210114421416234 12.838207918539362\n",
      "epoch  280 0.9207415803108808 12.833739067400476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[ 11.37254902  36.07843137  49.01960784  67.05882353  81.17647059\n",
      " 100.        ]\n",
      "start training set generation\n",
      "37436\n",
      "9360\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8616224315068494 27.551975949169858\n",
      "epoch  20 0.9173266267123288 13.328628926652748\n",
      "epoch  40 0.9190122003424658 13.09880733122565\n",
      "epoch  60 0.9192797517123288 12.99384637074928\n",
      "epoch  80 0.9198683647260274 12.932312400373696\n",
      "epoch  100 0.9197345890410958 12.95065157666598\n",
      "epoch  120 0.918851669520548 12.932960689476088\n",
      "epoch  140 0.9197078339041096 12.870305826810943\n",
      "epoch  160 0.9197880993150684 12.89352347426219\n",
      "epoch  180 0.9196008133561644 12.893591463565828\n",
      "epoch  200 0.9200288955479452 12.912156512884248\n",
      "epoch  220 0.9191459760273972 12.937602321579037\n",
      "10\n",
      "[ 22.35294118  41.17647059  55.29411765  67.05882353  86.2745098\n",
      " 100.        ]\n",
      "start training set generation\n",
      "38352\n",
      "9589\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.7264190317195326 43.91523056157641\n",
      "epoch  20 0.8303683222036727 24.98642820189513\n",
      "epoch  40 0.8320116861435726 24.55932790409146\n",
      "epoch  60 0.8310465358931552 24.485806812229065\n",
      "epoch  80 0.8315943238731218 24.43350974068618\n",
      "epoch  100 0.8317508347245409 24.36344675150059\n",
      "epoch  120 0.8315421535893155 24.325814473211075\n",
      "epoch  140 0.8318290901502504 24.30173766115471\n",
      "epoch  160 0.8321681969949917 24.2971995931635\n",
      "epoch  180 0.8318812604340567 24.252884821820135\n",
      "epoch  200 0.8314378130217028 24.26530076824566\n",
      "epoch  220 0.8313334724540902 24.259135523304135\n",
      "epoch  240 0.8316986644407346 24.271286117413606\n",
      "epoch  260 0.8318030050083473 24.228067622558886\n",
      "epoch  280 0.8333420283806344 24.203194831567934\n",
      "epoch  300 0.8327420701168614 24.292843245504695\n",
      "epoch  320 0.8310204507512521 24.23571601415516\n",
      "epoch  340 0.8302900667779632 24.23255017683383\n",
      "11\n",
      "[ 11.37254902  36.07843137  57.25490196  70.19607843  82.35294118\n",
      " 100.        ]\n",
      "start training set generation\n",
      "38412\n",
      "9604\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.817734375 33.104919981956456\n",
      "epoch  20 0.8862239583333333 17.374841361840545\n",
      "epoch  40 0.8880729166666667 17.071986973285664\n",
      "epoch  60 0.8892708333333333 16.992086352109915\n",
      "epoch  80 0.888515625 16.971130371093746\n",
      "epoch  100 0.8897135416666667 16.985676415761308\n",
      "epoch  120 0.8889583333333333 16.962381976445506\n",
      "epoch  140 0.8897916666666666 16.888584508101154\n",
      "epoch  160 0.8891145833333334 16.93491818189621\n",
      "12\n",
      "[ 12.15686275  35.29411765  54.11764706  75.29411765  89.01960784\n",
      " 100.        ]\n",
      "start training set generation\n",
      "38234\n",
      "9559\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8083909128978225 34.27828312718888\n",
      "epoch  20 0.8855998743718593 17.407422759824467\n",
      "epoch  40 0.8875628140703518 17.090649615979483\n",
      "epoch  60 0.8880077470686767 17.060754301559996\n",
      "epoch  80 0.8877983668341709 16.96768303492558\n",
      "epoch  100 0.8891331658291457 16.90525866193785\n",
      "epoch  120 0.8885050251256281 16.87927464224786\n",
      "epoch  140 0.8885835427135679 16.902377028760807\n",
      "epoch  160 0.8890546482412061 16.897664868052917\n",
      "epoch  180 0.8885311976549414 16.88176301256497\n",
      "epoch  200 0.8895519262981575 16.900239019537683\n",
      "epoch  220 0.8895519262981575 16.846313877521034\n",
      "epoch  240 0.8897613065326633 16.857957776866783\n",
      "epoch  260 0.8894734087102177 16.837452584175587\n",
      "epoch  280 0.8882694723618091 16.871958352413206\n",
      "epoch  300 0.8882432998324958 16.86838737804086\n",
      "epoch  320 0.8887667504187605 16.81202324071723\n",
      "epoch  340 0.889839824120603 16.81597034735496\n",
      "13\n",
      "[ 12.15686275  22.35294118  41.17647059  60.39215686  85.09803922\n",
      " 100.        ]\n",
      "start training set generation\n",
      "39045\n",
      "9762\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.6857069672131147 53.265417649316014\n",
      "epoch  20 0.8258965163934426 26.27736498723266\n",
      "epoch  40 0.8277920081967213 25.703316110079395\n",
      "epoch  60 0.8277407786885246 25.41611620168218\n",
      "epoch  80 0.8282530737704918 25.377492418445524\n",
      "epoch  100 0.8268186475409836 25.33321665779489\n",
      "epoch  120 0.8291752049180328 25.336581348982012\n",
      "epoch  140 0.8282274590163935 25.261618415644925\n",
      "epoch  160 0.8276383196721312 25.14864884204554\n",
      "epoch  180 0.8272284836065574 25.238599330089116\n",
      "epoch  200 0.8286372950819673 25.21658937891976\n",
      "14\n",
      "[ 15.29411765  39.21568627  52.15686275  63.1372549   75.29411765\n",
      " 100.        ]\n",
      "start training set generation\n",
      "38720\n",
      "9681\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.7825154958677686 38.30684497297298\n",
      "epoch  20 0.8613119834710744 21.276778362999277\n",
      "epoch  40 0.8604338842975207 20.985408773501057\n",
      "epoch  60 0.862603305785124 20.828604835321094\n",
      "epoch  80 0.8616219008264463 20.771482317900826\n",
      "epoch  100 0.8632231404958678 20.643729050691462\n",
      "epoch  120 0.8636880165289256 20.73772862804825\n",
      "epoch  140 0.8638429752066116 20.655229767097914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "[ 11.37254902  35.29411765  51.37254902  72.15686275  82.35294118\n",
      " 100.        ]\n",
      "start training set generation\n",
      "38607\n",
      "9652\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.7959939883913765 37.17187361930735\n",
      "epoch  20 0.8724087893864013 19.728059391477235\n",
      "epoch  40 0.8751295605306799 19.378710524557416\n",
      "epoch  60 0.8751295605306799 19.23642322910366\n",
      "epoch  80 0.8764251658374793 19.133099336133853\n",
      "epoch  100 0.8765288142620232 19.099087530107642\n",
      "epoch  120 0.8764510779436152 19.065185939099262\n",
      "epoch  140 0.8762956053067993 19.086090892899303\n",
      "epoch  160 0.8767101990049752 19.023887321130548\n",
      "epoch  180 0.8762437810945274 19.037382294289493\n",
      "epoch  200 0.8762178689883914 19.012083539124543\n",
      "epoch  220 0.8764251658374793 18.94103541223961\n",
      "epoch  240 0.8771247927031509 18.969653898210666\n",
      "epoch  260 0.876762023217247 18.94659600961661\n",
      "epoch  280 0.8773580016583747 18.967051510787133\n",
      "16\n",
      "[ 11.37254902  36.07843137  60.39215686  71.37254902  83.1372549\n",
      " 100.        ]\n",
      "start training set generation\n",
      "38490\n",
      "9623\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.818609608985025 32.41300855341451\n",
      "epoch  20 0.8915869384359401 16.771845680306626\n",
      "epoch  40 0.8931468386023295 16.479596374435566\n",
      "epoch  60 0.8951227121464226 16.335579559529272\n",
      "epoch  80 0.894446755407654 16.285131068872346\n",
      "epoch  100 0.8934328202995009 16.336592695677325\n",
      "epoch  120 0.8950707154742097 16.250614165466352\n",
      "epoch  140 0.8937707986688852 16.325754553625046\n",
      "epoch  160 0.895460690515807 16.22942291043958\n",
      "epoch  180 0.895356697171381 16.264051177140704\n",
      "epoch  200 0.8940307820299501 16.267468009732898\n",
      "epoch  220 0.8945247504159733 16.277636654960123\n",
      "17\n",
      "[ 11.37254902  35.29411765  55.29411765  66.2745098   80.39215686\n",
      " 100.        ]\n",
      "start training set generation\n",
      "38067\n",
      "9517\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8208912037037037 31.10456722593463\n",
      "epoch  20 0.8952283249158249 16.27994375758702\n",
      "epoch  40 0.8957807239057239 15.94327425153971\n",
      "epoch  60 0.89659617003367 15.831968032952512\n",
      "epoch  80 0.8973063973063973 15.783958958455607\n",
      "epoch  100 0.896780303030303 15.757181046386359\n",
      "epoch  120 0.8973063973063973 15.693597978213019\n",
      "epoch  140 0.8966750841750841 15.7520164150983\n",
      "epoch  160 0.8969381313131313 15.712944957945082\n",
      "epoch  180 0.897700968013468 15.643598601472899\n",
      "epoch  200 0.8970170454545454 15.692653549239294\n",
      "epoch  220 0.8973853114478114 15.672001315287067\n",
      "epoch  240 0.898069234006734 15.636442163576579\n",
      "epoch  260 0.8968855218855218 15.651385394009678\n",
      "epoch  280 0.8980955387205387 15.677552212769736\n",
      "18\n",
      "[ 13.33333333  38.03921569  53.33333333  65.09803922  89.01960784\n",
      " 100.        ]\n",
      "start training set generation\n",
      "37120\n",
      "9281\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8212015086206896 30.760170277233783\n",
      "epoch  20 0.8999461206896552 16.022180641108562\n",
      "epoch  40 0.8996497844827587 15.80150927264115\n",
      "epoch  60 0.9004849137931035 15.71289293848235\n",
      "epoch  80 0.9008081896551724 15.638283238739803\n",
      "epoch  100 0.9015625 15.622067476141043\n",
      "epoch  120 0.9016163793103448 15.6176842212677\n",
      "epoch  140 0.9015625 15.547565603256226\n",
      "epoch  160 0.9024784482758621 15.541365443426987\n",
      "epoch  180 0.9016702586206896 15.529441350081871\n",
      "epoch  200 0.9014008620689655 15.546032570148336\n",
      "epoch  220 0.9022359913793103 15.45129257317247\n",
      "epoch  240 0.9009698275862069 15.490192900032833\n",
      "epoch  260 0.9022629310344827 15.496972019096901\n",
      "epoch  280 0.9022359913793103 15.447775677976937\n",
      "epoch  300 0.9029364224137931 15.415192114073655\n",
      "epoch  320 0.9017510775862069 15.453696435073326\n",
      "epoch  340 0.9021012931034482 15.46552147947509\n",
      "epoch  360 0.9022629310344827 15.409953817827947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "[ 11.37254902  36.07843137  60.39215686  72.15686275  88.23529412\n",
      " 100.        ]\n",
      "start training set generation\n",
      "38690\n",
      "9673\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8383174668874173 27.910358627900383\n",
      "epoch  20 0.9124586092715232 13.862831662822238\n",
      "epoch  40 0.9138555463576159 13.623106589380473\n",
      "epoch  60 0.9142953228476821 13.559240381449266\n",
      "epoch  80 0.9143470612582781 13.494475870337707\n",
      "epoch  100 0.9138296771523179 13.51001650094986\n",
      "epoch  120 0.9140625 13.445376254075414\n",
      "epoch  140 0.9142177152317881 13.412488545803038\n",
      "epoch  160 0.9145281456953642 13.391609191499803\n",
      "epoch  180 0.9137779387417219 13.407287665155547\n",
      "epoch  200 0.9145798841059603 13.372084583667725\n",
      "epoch  220 0.9142177152317881 13.352937897704297\n",
      "epoch  240 0.9145022764900662 13.375663041279015\n",
      "epoch  260 0.914010761589404 13.374250258041533\n",
      "epoch  280 0.9131829470198676 13.370052606854227\n",
      "epoch  300 0.914036630794702 13.331628524704492\n",
      "epoch  320 0.9145022764900662 13.328110603307257\n",
      "epoch  340 0.9143211920529801 13.331240542282334\n",
      "epoch  360 0.9153559602649006 13.301180691908531\n",
      "epoch  380 0.914036630794702 13.328091033247127\n",
      "20\n",
      "[ 10.19607843  28.23529412  45.09803922  67.05882353  78.03921569\n",
      " 100.        ]\n",
      "start training set generation\n",
      "37980\n",
      "9495\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8339744940978078 29.996030004993457\n",
      "epoch  20 0.9121785413153457 14.00481637855002\n",
      "epoch  40 0.9141547217537943 13.637345329303963\n",
      "epoch  60 0.9137858347386172 13.561536353916981\n",
      "epoch  80 0.9143655143338955 13.499857608222639\n",
      "epoch  100 0.9137331365935919 13.463919209388614\n",
      "epoch  120 0.9148397976391232 13.42454057037328\n",
      "epoch  140 0.9145763069139966 13.447726365486643\n",
      "epoch  160 0.9154985244519392 13.417727015271753\n",
      "epoch  180 0.915893760539629 13.42396695698292\n",
      "epoch  200 0.9158147133220911 13.394867011708715\n",
      "epoch  220 0.9143655143338955 13.36401567169627\n",
      "epoch  240 0.9158674114671164 13.395933989127602\n",
      "epoch  260 0.9152086846543002 13.404146144603194\n",
      "epoch  280 0.9148134485666105 13.379896336019947\n",
      "21\n",
      "[ 10.19607843  32.15686275  45.09803922  64.31372549  88.23529412\n",
      " 100.        ]\n",
      "start training set generation\n",
      "38784\n",
      "9697\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8565903465346535 25.540002701699553\n",
      "epoch  20 0.9260519801980198 11.865445504487539\n",
      "epoch  40 0.9265676567656765 11.723142797403993\n",
      "epoch  60 0.9270833333333334 11.691152959766958\n",
      "epoch  80 0.9263613861386139 11.63247717016995\n",
      "epoch  100 0.9280631188118812 11.632770568230757\n",
      "epoch  120 0.9283725247524752 11.609175526269595\n",
      "epoch  140 0.9265418729372937 11.587688560533055\n",
      "epoch  160 0.9275990099009901 11.591067510862947\n",
      "epoch  180 0.9274958745874587 11.57886165714893\n",
      "epoch  200 0.928088902640264 11.585911698467273\n",
      "epoch  220 0.928733498349835 11.54121271415119\n",
      "epoch  240 0.9282436056105611 11.527815961995149\n",
      "epoch  260 0.9276247937293729 11.546508696213024\n",
      "epoch  280 0.92777949669967 11.512269806153695\n",
      "epoch  300 0.9276505775577558 11.520550413493671\n",
      "epoch  320 0.9278826320132013 11.500960834742374\n",
      "epoch  340 0.9272122524752475 11.55242542897907\n",
      "epoch  360 0.927934199669967 11.50650670819551\n",
      "epoch  380 0.9277279290429042 11.519609392279447\n",
      "epoch  400 0.9273927392739274 11.509147053111114\n",
      "epoch  420 0.9274185231023102 11.506871199450485\n",
      "epoch  440 0.9278310643564357 11.473129384981924\n",
      "22\n",
      "[ 11.37254902  36.07843137  47.05882353  57.25490196  76.07843137\n",
      " 100.        ]\n",
      "start training set generation\n",
      "38029\n",
      "9508\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8575073653198653 24.636588322995888\n",
      "epoch  20 0.92739898989899 11.968659315446407\n",
      "epoch  40 0.9282407407407407 11.772763720265141\n",
      "epoch  60 0.9278724747474747 11.721885709650186\n",
      "epoch  80 0.9290035774410774 11.647651787960166\n",
      "epoch  100 0.9273463804713805 11.613976938555936\n",
      "epoch  120 0.9273726851851852 11.608108193786062\n",
      "epoch  140 0.9282933501683501 11.51655014355977\n",
      "epoch  160 0.9287142255892256 11.547129982649675\n",
      "epoch  180 0.9282933501683501 11.540121790535917\n",
      "epoch  200 0.9281881313131313 11.475864203690676\n",
      "epoch  220 0.9276883417508418 11.507753388648878\n",
      "epoch  240 0.9282933501683501 11.495879596331307\n",
      "epoch  260 0.9286353114478114 11.45335905921178\n",
      "epoch  280 0.928398569023569 11.451152467165727\n",
      "epoch  300 0.9281355218855218 11.434829754460141\n",
      "epoch  320 0.9286090067340067 11.423248473241273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "[ 10.19607843  34.11764706  50.19607843  74.11764706  88.23529412\n",
      " 100.        ]\n",
      "start training set generation\n",
      "38016\n",
      "9504\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8668718434343434 22.80845195275768\n",
      "epoch  20 0.9401567760942761 9.689211307952693\n",
      "epoch  40 0.9412615740740741 9.555730993097468\n",
      "epoch  60 0.9418665824915825 9.493417842620946\n",
      "epoch  80 0.9411826599326599 9.414322056152209\n",
      "epoch  100 0.9414720117845118 9.401695805366582\n",
      "epoch  120 0.9427346380471381 9.369717185344763\n",
      "epoch  140 0.9430765993265994 9.344563386255647\n",
      "epoch  160 0.9423926767676768 9.346427648557155\n",
      "epoch  180 0.9433396464646465 9.281499331045636\n",
      "epoch  200 0.9432607323232324 9.323591645719222\n",
      "epoch  220 0.9431292087542088 9.266837170830483\n",
      "epoch  240 0.9431292087542088 9.24566948132885\n",
      "epoch  260 0.9438657407407407 9.233990525155761\n",
      "epoch  280 0.9444707491582491 9.187443538346285\n",
      "epoch  300 0.94347117003367 9.260088423687204\n",
      "epoch  320 0.9429187710437711 9.230213113906807\n",
      "epoch  340 0.9431292087542088 9.249964786900408\n",
      "epoch  360 0.9436816077441077 9.220663595079184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "for timeIndex in range(len(normalLumping)):\n",
    "    if len(normalLumping[timeIndex]) == 0:\n",
    "        continue\n",
    "    \n",
    "    print(timeIndex)\n",
    "    boundaries = np.array([])\n",
    "    for i in range(1, len(normalLumping[0][0][3])):\n",
    "        bound = normalLumping[timeIndex][0][3][i] + 1\n",
    "        counter = 0\n",
    "        for j in range(len(percentageArray[timeIndex])):\n",
    "            if percentageArray[timeIndex][j][2] == False:\n",
    "                counter += 1\n",
    "            if counter == bound:\n",
    "                boundaries = np.append(boundaries, percentageArray[timeIndex][j][1])\n",
    "                break\n",
    "    boundaries = np.append(boundaries,100)\n",
    "    print(boundaries)\n",
    "    \n",
    "    XArraysForLearning, YArraysForLearning, XArraysForTesting, YArraysForTesting, boundaries = dataPreparation(\n",
    "        data, timeIndex, 30, boundaries)\n",
    "\n",
    "    print(\"starting tensor\")\n",
    "    lossFunctionBoolean = 0\n",
    "    accuracy_result, penaltyValue, precision, recall, f1Score = tensorFlowLossFunction(\n",
    "        lossFunctionBoolean, XArraysForLearning, YArraysForLearning, XArraysForTesting, \n",
    "        YArraysForTesting, boundaries)\n",
    "    \n",
    "    result_25_10_6class_60min_DataFrameNoPenalty.loc[timeIndex][\"accuracy\"] = accuracy_result\n",
    "    result_25_10_6class_60min_DataFrameNoPenalty.loc[timeIndex][\"penalty\"] = penaltyValue\n",
    "    result_25_10_6class_60min_DataFrameNoPenalty.loc[timeIndex][\"precision\"] = precision\n",
    "    result_25_10_6class_60min_DataFrameNoPenalty.loc[timeIndex][\"recall\"] = recall\n",
    "    result_25_10_6class_60min_DataFrameNoPenalty.loc[timeIndex][\"f1Score\"] = f1Score\n",
    "    result_25_10_6class_60min_DataFrameNoPenalty.loc[timeIndex][\"boundaries\"] = boundaries\n",
    "    result_25_10_6class_60min_DataFrameNoPenalty.loc[timeIndex][\"lumpAprox\"] = normalLumping[timeIndex][0][0]\n",
    "    result_25_10_6class_60min_DataFrameNoPenalty.loc[timeIndex][\"lumpError\"] = normalLumping[timeIndex][0][1]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>penalty</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1Score</th>\n",
       "      <th>boundaries</th>\n",
       "      <th>lumpAprox</th>\n",
       "      <th>lumpError</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.937731</td>\n",
       "      <td>23.4727</td>\n",
       "      <td>0.936423</td>\n",
       "      <td>0.937731</td>\n",
       "      <td>0.934015</td>\n",
       "      <td>[10.196078431372554, 32.156862745097996, 51.37...</td>\n",
       "      <td>1</td>\n",
       "      <td>44.9435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.935359</td>\n",
       "      <td>27.9766</td>\n",
       "      <td>0.934413</td>\n",
       "      <td>0.935359</td>\n",
       "      <td>0.933699</td>\n",
       "      <td>[10.196078431372554, 34.11764705882348, 48.235...</td>\n",
       "      <td>1</td>\n",
       "      <td>22.8649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.961534</td>\n",
       "      <td>15.2717</td>\n",
       "      <td>0.960621</td>\n",
       "      <td>0.961534</td>\n",
       "      <td>0.961077</td>\n",
       "      <td>[24.31372549019606, 42.35294117647051, 54.1176...</td>\n",
       "      <td>1</td>\n",
       "      <td>30.3948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.953327</td>\n",
       "      <td>8.23176</td>\n",
       "      <td>0.957093</td>\n",
       "      <td>0.953327</td>\n",
       "      <td>0.954596</td>\n",
       "      <td>[23.13725490196077, 34.11764705882348, 48.2352...</td>\n",
       "      <td>1</td>\n",
       "      <td>21.3463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.956773</td>\n",
       "      <td>9.23039</td>\n",
       "      <td>0.960073</td>\n",
       "      <td>0.956773</td>\n",
       "      <td>0.957733</td>\n",
       "      <td>[24.31372549019606, 35.29411764705877, 51.3725...</td>\n",
       "      <td>1</td>\n",
       "      <td>25.3972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.931411</td>\n",
       "      <td>26.9434</td>\n",
       "      <td>0.930578</td>\n",
       "      <td>0.931411</td>\n",
       "      <td>0.928441</td>\n",
       "      <td>[10.196078431372554, 34.11764705882348, 51.372...</td>\n",
       "      <td>1</td>\n",
       "      <td>21.7719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.935813</td>\n",
       "      <td>25.3296</td>\n",
       "      <td>0.934784</td>\n",
       "      <td>0.935813</td>\n",
       "      <td>0.93425</td>\n",
       "      <td>[10.196078431372554, 32.156862745097996, 50.19...</td>\n",
       "      <td>1</td>\n",
       "      <td>27.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.917429</td>\n",
       "      <td>35.3142</td>\n",
       "      <td>0.913065</td>\n",
       "      <td>0.917429</td>\n",
       "      <td>0.912977</td>\n",
       "      <td>[11.372549019607849, 36.07843137254896, 50.196...</td>\n",
       "      <td>1</td>\n",
       "      <td>40.4272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.921626</td>\n",
       "      <td>44.537</td>\n",
       "      <td>0.91964</td>\n",
       "      <td>0.921626</td>\n",
       "      <td>0.920215</td>\n",
       "      <td>[13.333333333333341, 37.25490196078425, 60.392...</td>\n",
       "      <td>1</td>\n",
       "      <td>40.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.910791</td>\n",
       "      <td>31.7522</td>\n",
       "      <td>0.908068</td>\n",
       "      <td>0.910791</td>\n",
       "      <td>0.906933</td>\n",
       "      <td>[11.372549019607849, 36.07843137254896, 49.019...</td>\n",
       "      <td>1</td>\n",
       "      <td>41.7307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.818959</td>\n",
       "      <td>51.1172</td>\n",
       "      <td>0.833622</td>\n",
       "      <td>0.818959</td>\n",
       "      <td>0.819492</td>\n",
       "      <td>[22.352941176470576, 41.17647058823522, 55.294...</td>\n",
       "      <td>0.513672</td>\n",
       "      <td>36.5657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.87828</td>\n",
       "      <td>59.4955</td>\n",
       "      <td>0.880289</td>\n",
       "      <td>0.87828</td>\n",
       "      <td>0.877204</td>\n",
       "      <td>[11.372549019607849, 36.07843137254896, 57.254...</td>\n",
       "      <td>0.571289</td>\n",
       "      <td>35.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.885239</td>\n",
       "      <td>56.7368</td>\n",
       "      <td>0.885605</td>\n",
       "      <td>0.885239</td>\n",
       "      <td>0.88468</td>\n",
       "      <td>[12.156862745098046, 35.29411764705877, 54.117...</td>\n",
       "      <td>1</td>\n",
       "      <td>40.5454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.824524</td>\n",
       "      <td>81.8684</td>\n",
       "      <td>0.822571</td>\n",
       "      <td>0.824524</td>\n",
       "      <td>0.82161</td>\n",
       "      <td>[12.156862745098046, 22.352941176470576, 41.17...</td>\n",
       "      <td>0.821777</td>\n",
       "      <td>43.5166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.86582</td>\n",
       "      <td>52.5192</td>\n",
       "      <td>0.858352</td>\n",
       "      <td>0.86582</td>\n",
       "      <td>0.860497</td>\n",
       "      <td>[15.294117647058833, 39.215686274509736, 52.15...</td>\n",
       "      <td>0.86377</td>\n",
       "      <td>37.3944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.877435</td>\n",
       "      <td>53.6583</td>\n",
       "      <td>0.875352</td>\n",
       "      <td>0.877435</td>\n",
       "      <td>0.873468</td>\n",
       "      <td>[11.372549019607849, 35.29411764705877, 51.372...</td>\n",
       "      <td>0.777832</td>\n",
       "      <td>41.1748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.8939</td>\n",
       "      <td>65.5092</td>\n",
       "      <td>0.889079</td>\n",
       "      <td>0.8939</td>\n",
       "      <td>0.886184</td>\n",
       "      <td>[11.372549019607849, 36.07843137254896, 60.392...</td>\n",
       "      <td>0.692383</td>\n",
       "      <td>33.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.891983</td>\n",
       "      <td>48.563</td>\n",
       "      <td>0.887866</td>\n",
       "      <td>0.891983</td>\n",
       "      <td>0.884801</td>\n",
       "      <td>[11.372549019607849, 35.29411764705877, 55.294...</td>\n",
       "      <td>0.688965</td>\n",
       "      <td>38.4023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.89861</td>\n",
       "      <td>57.321</td>\n",
       "      <td>0.896579</td>\n",
       "      <td>0.89861</td>\n",
       "      <td>0.896954</td>\n",
       "      <td>[13.333333333333341, 38.039215686274446, 53.33...</td>\n",
       "      <td>1</td>\n",
       "      <td>44.4639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.916365</td>\n",
       "      <td>47.6845</td>\n",
       "      <td>0.913767</td>\n",
       "      <td>0.916365</td>\n",
       "      <td>0.912562</td>\n",
       "      <td>[11.372549019607849, 36.07843137254896, 60.392...</td>\n",
       "      <td>0.666992</td>\n",
       "      <td>35.3279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.907846</td>\n",
       "      <td>31.7606</td>\n",
       "      <td>0.905592</td>\n",
       "      <td>0.907846</td>\n",
       "      <td>0.904032</td>\n",
       "      <td>[10.196078431372554, 28.235294117647026, 45.09...</td>\n",
       "      <td>1</td>\n",
       "      <td>39.3911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.924616</td>\n",
       "      <td>22.8687</td>\n",
       "      <td>0.919776</td>\n",
       "      <td>0.924616</td>\n",
       "      <td>0.914047</td>\n",
       "      <td>[10.196078431372554, 32.156862745097996, 45.09...</td>\n",
       "      <td>1</td>\n",
       "      <td>41.2079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.928376</td>\n",
       "      <td>35.4776</td>\n",
       "      <td>0.926995</td>\n",
       "      <td>0.928376</td>\n",
       "      <td>0.927251</td>\n",
       "      <td>[11.372549019607849, 36.07843137254896, 47.058...</td>\n",
       "      <td>0.666992</td>\n",
       "      <td>28.9871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.940762</td>\n",
       "      <td>27.9658</td>\n",
       "      <td>0.938511</td>\n",
       "      <td>0.940762</td>\n",
       "      <td>0.937309</td>\n",
       "      <td>[10.196078431372554, 34.11764705882348, 50.196...</td>\n",
       "      <td>1</td>\n",
       "      <td>35.6699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  penalty precision    recall   f1Score  \\\n",
       "0   0.937731  23.4727  0.936423  0.937731  0.934015   \n",
       "1   0.935359  27.9766  0.934413  0.935359  0.933699   \n",
       "2   0.961534  15.2717  0.960621  0.961534  0.961077   \n",
       "3   0.953327  8.23176  0.957093  0.953327  0.954596   \n",
       "4   0.956773  9.23039  0.960073  0.956773  0.957733   \n",
       "5   0.931411  26.9434  0.930578  0.931411  0.928441   \n",
       "6   0.935813  25.3296  0.934784  0.935813   0.93425   \n",
       "7   0.917429  35.3142  0.913065  0.917429  0.912977   \n",
       "8   0.921626   44.537   0.91964  0.921626  0.920215   \n",
       "9   0.910791  31.7522  0.908068  0.910791  0.906933   \n",
       "10  0.818959  51.1172  0.833622  0.818959  0.819492   \n",
       "11   0.87828  59.4955  0.880289   0.87828  0.877204   \n",
       "12  0.885239  56.7368  0.885605  0.885239   0.88468   \n",
       "13  0.824524  81.8684  0.822571  0.824524   0.82161   \n",
       "14   0.86582  52.5192  0.858352   0.86582  0.860497   \n",
       "15  0.877435  53.6583  0.875352  0.877435  0.873468   \n",
       "16    0.8939  65.5092  0.889079    0.8939  0.886184   \n",
       "17  0.891983   48.563  0.887866  0.891983  0.884801   \n",
       "18   0.89861   57.321  0.896579   0.89861  0.896954   \n",
       "19  0.916365  47.6845  0.913767  0.916365  0.912562   \n",
       "20  0.907846  31.7606  0.905592  0.907846  0.904032   \n",
       "21  0.924616  22.8687  0.919776  0.924616  0.914047   \n",
       "22  0.928376  35.4776  0.926995  0.928376  0.927251   \n",
       "23  0.940762  27.9658  0.938511  0.940762  0.937309   \n",
       "\n",
       "                                           boundaries lumpAprox lumpError  \n",
       "0   [10.196078431372554, 32.156862745097996, 51.37...         1   44.9435  \n",
       "1   [10.196078431372554, 34.11764705882348, 48.235...         1   22.8649  \n",
       "2   [24.31372549019606, 42.35294117647051, 54.1176...         1   30.3948  \n",
       "3   [23.13725490196077, 34.11764705882348, 48.2352...         1   21.3463  \n",
       "4   [24.31372549019606, 35.29411764705877, 51.3725...         1   25.3972  \n",
       "5   [10.196078431372554, 34.11764705882348, 51.372...         1   21.7719  \n",
       "6   [10.196078431372554, 32.156862745097996, 50.19...         1     27.74  \n",
       "7   [11.372549019607849, 36.07843137254896, 50.196...         1   40.4272  \n",
       "8   [13.333333333333341, 37.25490196078425, 60.392...         1    40.969  \n",
       "9   [11.372549019607849, 36.07843137254896, 49.019...         1   41.7307  \n",
       "10  [22.352941176470576, 41.17647058823522, 55.294...  0.513672   36.5657  \n",
       "11  [11.372549019607849, 36.07843137254896, 57.254...  0.571289     35.73  \n",
       "12  [12.156862745098046, 35.29411764705877, 54.117...         1   40.5454  \n",
       "13  [12.156862745098046, 22.352941176470576, 41.17...  0.821777   43.5166  \n",
       "14  [15.294117647058833, 39.215686274509736, 52.15...   0.86377   37.3944  \n",
       "15  [11.372549019607849, 35.29411764705877, 51.372...  0.777832   41.1748  \n",
       "16  [11.372549019607849, 36.07843137254896, 60.392...  0.692383    33.401  \n",
       "17  [11.372549019607849, 35.29411764705877, 55.294...  0.688965   38.4023  \n",
       "18  [13.333333333333341, 38.039215686274446, 53.33...         1   44.4639  \n",
       "19  [11.372549019607849, 36.07843137254896, 60.392...  0.666992   35.3279  \n",
       "20  [10.196078431372554, 28.235294117647026, 45.09...         1   39.3911  \n",
       "21  [10.196078431372554, 32.156862745097996, 45.09...         1   41.2079  \n",
       "22  [11.372549019607849, 36.07843137254896, 47.058...  0.666992   28.9871  \n",
       "23  [10.196078431372554, 34.11764705882348, 50.196...         1   35.6699  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_25_10_6class_60min_DataFrameNoPenalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"/home/sepehr/thesis/APDataML/result_25_10_6class_60min_DataFrameNoPenalty.pickle\"\n",
    "with open(name, 'wb') as handle:\n",
    "    pickle.dump(result_25_10_6class_60min_DataFrameNoPenalty, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"/home/sepehr/thesis/APDataML/pickles/4normal_25-10_lumping_60min.pickle\"\n",
    "with open(name, 'rb') as handle:\n",
    "    normalLumping = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentageArray = []\n",
    "for i in range(len(normalLumping)):\n",
    "    name = \"/home/sepehr/thesis/APDataML/pickles/4normal_25-10_lumping_60min_percentage_\" + str(i) + \".pickle\"\n",
    "    with open(name, 'rb') as handle:\n",
    "        percentageArray.append(pickle.load(handle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyResult = [np.inf for i in range(len(normalLumping))]\n",
    "penaltyResult = [np.inf for i in range(len(normalLumping))]\n",
    "precisionResult = [np.inf for i in range(len(normalLumping))]\n",
    "recallResult = [np.inf for i in range(len(normalLumping))]\n",
    "f1ScoreResult = [np.inf for i in range(len(normalLumping))]\n",
    "boundariesResult = [np.inf for i in range(len(normalLumping))]\n",
    "lumpAproxResult = [np.inf for i in range(len(normalLumping))]\n",
    "lumpErrorResult = [np.inf for i in range(len(normalLumping))]\n",
    "\n",
    "\n",
    "testDataFrame = {\"accuracy\": accuracyResult, \"penalty\": penaltyResult, \"precision\": precisionResult, \n",
    "                 \"recall\": recallResult, \"f1Score\": f1ScoreResult, \"boundaries\": boundariesResult, \n",
    "                 \"lumpAprox\": lumpAproxResult, \"lumpError\": lumpErrorResult}\n",
    "\n",
    "result_25_10_5class_60min_DataFrameNoPenalty = pd.DataFrame(testDataFrame)\n",
    "result_25_10_5class_60min_DataFrameNoPenalty = result_25_10_5class_60min_DataFrameNoPenalty.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[ 10.19607843  32.15686275  51.37254902  76.07843137 100.        ]\n",
      "start training set generation\n",
      "37896\n",
      "9475\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.887035472972973 19.362765431404114\n",
      "epoch  20 0.9337257179054054 10.25008978996728\n",
      "epoch  40 0.9346494932432432 10.06497000037013\n",
      "epoch  60 0.9343591638513513 9.985421789659046\n",
      "epoch  80 0.935546875 9.905917656582748\n",
      "epoch  100 0.9351245777027027 9.894789617609339\n",
      "epoch  120 0.9359427787162162 9.878713078192751\n",
      "epoch  140 0.9357316300675675 9.815593219890786\n",
      "epoch  160 0.9361539273648649 9.798166733738555\n",
      "epoch  180 0.935863597972973 9.812560447969943\n",
      "epoch  200 0.9367345861486487 9.772245322127603\n",
      "epoch  220 0.9359163851351351 9.762442327633096\n",
      "epoch  240 0.9359955658783784 9.73997388880801\n",
      "epoch  260 0.9361275337837838 9.724800645499618\n",
      "epoch  280 0.9369457347972973 9.714753261289088\n",
      "epoch  300 0.9357052364864865 9.687306598835704\n",
      "epoch  320 0.935863597972973 9.679338574812217\n",
      "epoch  340 0.9359691722972973 9.666549245650714\n",
      "epoch  360 0.9357052364864865 9.689767293430657\n",
      "epoch  380 0.9362595016891891 9.695936962962152\n",
      "epoch  400 0.935230152027027 9.66201980532826\n",
      "epoch  420 0.9371040962837838 9.638158939577439\n",
      "epoch  440 0.9369457347972973 9.6368708956886\n",
      "epoch  460 0.9361011402027027 9.633804290278542\n",
      "epoch  480 0.9357316300675675 9.695059271277614\n",
      "epoch  500 0.9364178631756757 9.669645976778614\n",
      "epoch  520 0.9366817989864865 9.60879589939439\n",
      "epoch  540 0.9360483530405406 9.670526405444024\n",
      "epoch  560 0.9366026182432432 9.637218309415356\n",
      "epoch  580 0.9363386824324325 9.654122196339268\n",
      "epoch  600 0.9361539273648649 9.627855612619513\n",
      "epoch  620 0.9368137668918919 9.59812005991871\n",
      "epoch  640 0.9358108108108109 9.626281142436163\n",
      "1\n",
      "[ 10.19607843  34.11764706  51.37254902  76.07843137 100.        ]\n",
      "start training set generation\n",
      "38177\n",
      "9545\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8877149748322147 18.816489202064144\n",
      "epoch  20 0.9326499580536913 10.495911420591728\n",
      "epoch  40 0.9325713087248322 10.280410651592607\n",
      "epoch  60 0.9343540268456376 10.154378250141272\n",
      "epoch  80 0.9339607802013423 10.045957697317911\n",
      "epoch  100 0.9345899748322147 10.025813484751934\n",
      "epoch  120 0.9357434983221476 9.968547661032456\n",
      "epoch  140 0.9358745805369127 9.926987619208012\n",
      "epoch  160 0.934825922818792 9.880663526138212\n",
      "epoch  180 0.9357434983221476 9.857802566665933\n",
      "epoch  200 0.9363464765100671 9.82861301262907\n",
      "epoch  220 0.9362416107382551 9.78944117310863\n",
      "epoch  240 0.9368970218120806 9.76289438041265\n",
      "epoch  260 0.9360580956375839 9.724775295529586\n",
      "epoch  280 0.9361629614093959 9.72949107701346\n",
      "epoch  300 0.9363464765100671 9.704016837497681\n",
      "epoch  320 0.9362416107382551 9.72560612427309\n",
      "epoch  340 0.9364251258389261 9.69129105262308\n",
      "epoch  360 0.9363464765100671 9.706172359869782\n",
      "epoch  380 0.9368445889261745 9.636555155251653\n",
      "epoch  400 0.9365299916107382 9.63349533721105\n",
      "epoch  420 0.9370018875838926 9.620511901858679\n",
      "epoch  440 0.9363989093959731 9.660590516240804\n",
      "epoch  460 0.9365037751677853 9.596267559584351\n",
      "epoch  480 0.9363464765100671 9.60415920875216\n",
      "epoch  500 0.9371067533557047 9.571962196554917\n",
      "epoch  520 0.9371329697986577 9.58182288376276\n",
      "epoch  540 0.9372640520134228 9.594275939384564\n",
      "epoch  560 0.9367659395973155 9.546632365092337\n",
      "epoch  580 0.9369232382550335 9.549857723232877\n",
      "epoch  600 0.9375524328859061 9.54380908628439\n",
      "epoch  620 0.9372378355704698 9.574326685211004\n",
      "epoch  640 0.9372640520134228 9.541608527202735\n",
      "epoch  660 0.9368708053691275 9.532813045002468\n",
      "epoch  680 0.9378670302013423 9.487576440276722\n",
      "epoch  700 0.9372640520134228 9.540144531718827\n",
      "epoch  720 0.9377359479865772 9.55811969545862\n",
      "2\n",
      "[ 24.31372549  42.35294118  54.11764706  78.03921569 100.        ]\n",
      "start training set generation\n",
      "37746\n",
      "9437\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.9346084465195246 13.884976444503444\n",
      "epoch  20 0.9626485568760611 6.0875252075430115\n",
      "epoch  40 0.9633117572156197 5.9492689185919705\n",
      "epoch  60 0.9640545415959253 5.995769590291183\n",
      "epoch  80 0.9628077249575552 5.940412238316143\n",
      "epoch  100 0.9638157894736842 5.908898385251115\n",
      "epoch  120 0.9636300933786078 5.9052145893990655\n",
      "epoch  140 0.9631260611205433 5.887499573477666\n",
      "epoch  160 0.9640280135823429 5.887635957810186\n",
      "epoch  180 0.9634443972835314 5.838479611991011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[ 23.1372549   45.09803922  58.03921569  77.25490196 100.        ]\n",
      "start training set generation\n",
      "37448\n",
      "9363\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.9263888888888889 14.78594278148095\n",
      "epoch  20 0.9580929487179487 6.766827606951072\n",
      "epoch  40 0.9577724358974359 6.720401304807415\n",
      "epoch  60 0.9578258547008547 6.7218911857686505\n",
      "epoch  80 0.9574786324786325 6.681264342813413\n",
      "epoch  100 0.9583066239316239 6.667401195387552\n",
      "epoch  120 0.9578792735042735 6.648873195790834\n",
      "epoch  140 0.9577724358974359 6.636407656751126\n",
      "epoch  160 0.9574252136752137 6.652619663874305\n",
      "epoch  180 0.9576923076923077 6.687315318676142\n",
      "epoch  200 0.9586004273504274 6.6147340530004275\n",
      "4\n",
      "[ 24.31372549  49.01960784  61.17647059  84.31372549 100.        ]\n",
      "start training set generation\n",
      "38121\n",
      "9531\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.9385241596638656 12.332967809068057\n",
      "epoch  20 0.9635766806722689 5.800680131170934\n",
      "epoch  40 0.9634978991596639 5.735877922002007\n",
      "epoch  60 0.9633140756302521 5.709665478277605\n",
      "epoch  80 0.9647058823529412 5.675191879172285\n",
      "epoch  100 0.963655462184874 5.694744287619072\n",
      "epoch  120 0.963813025210084 5.688902013542272\n",
      "epoch  140 0.9640231092436975 5.671178096582913\n",
      "epoch  160 0.9641018907563025 5.652091645443139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[ 24.31372549  49.01960784  70.19607843  87.05882353 100.        ]\n",
      "start training set generation\n",
      "37322\n",
      "9331\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.9271548027444254 13.93108683221336\n",
      "epoch  20 0.9577079759862779 6.749562492808184\n",
      "epoch  40 0.9583512006861064 6.689880597652741\n",
      "epoch  60 0.9585656089193825 6.6598988621149\n",
      "epoch  80 0.958592409948542 6.623642228275384\n",
      "epoch  100 0.9590212264150944 6.609352930639045\n",
      "epoch  120 0.9593428387650086 6.572749107207074\n",
      "epoch  140 0.9591284305317325 6.593241237857944\n",
      "epoch  160 0.9588068181818182 6.577116946413424\n",
      "epoch  180 0.9592892367066895 6.560961232279427\n",
      "6\n",
      "[ 24.31372549  35.29411765  51.37254902  75.29411765 100.        ]\n",
      "start training set generation\n",
      "36891\n",
      "9223\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.9088270399305556 18.559003040194497\n",
      "epoch  20 0.9478624131944444 8.42265195544395\n",
      "epoch  40 0.9485948350694444 8.288845690795116\n",
      "epoch  60 0.9474826388888888 8.253891028256877\n",
      "epoch  80 0.94921875 8.175063431883855\n",
      "epoch  100 0.9493272569444444 8.165570290966157\n",
      "epoch  120 0.9482693142361112 8.141992931150718\n",
      "epoch  140 0.9485134548611112 8.15365821081732\n",
      "epoch  160 0.9494086371527778 8.115029625801574\n",
      "epoch  180 0.94873046875 8.117357177245943\n",
      "epoch  200 0.9489474826388888 8.098475609181634\n",
      "epoch  220 0.9486490885416666 8.154204481798732\n",
      "epoch  240 0.9492458767361112 8.098869005632055\n",
      "epoch  260 0.9491916232638888 8.119649783397715\n",
      "epoch  280 0.9494357638888888 8.100132009014482\n",
      "epoch  300 0.9485948350694444 8.145875301936439\n",
      "epoch  320 0.9490559895833334 8.101598916989227\n",
      "epoch  340 0.9494900173611112 8.06304759718478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "[ 11.37254902  36.07843137  55.29411765  79.21568627 100.        ]\n",
      "start training set generation\n",
      "36717\n",
      "9180\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8820080715532286 21.494343641124676\n",
      "epoch  20 0.9162303664921466 12.80181303490311\n",
      "epoch  40 0.9162849040139616 12.592863962912437\n",
      "epoch  60 0.9171847731239092 12.515150347305221\n",
      "epoch  80 0.9175392670157068 12.443853010057778\n",
      "epoch  100 0.9186027486910995 12.394055126017099\n",
      "epoch  120 0.918957242582897 12.398100443951542\n",
      "epoch  140 0.918739092495637 12.319068916180997\n",
      "epoch  160 0.9188754363001745 12.337575866289782\n",
      "epoch  180 0.9185482111692844 12.280776013878631\n",
      "epoch  200 0.9180846422338569 12.34099135723414\n",
      "epoch  220 0.9193935427574171 12.321439844983626\n",
      "epoch  240 0.918739092495637 12.328091170359244\n",
      "epoch  260 0.9184391361256544 12.311978051799745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[ 13.33333333  37.25490196  60.39215686  78.03921569 100.        ]\n",
      "start training set generation\n",
      "37100\n",
      "9276\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8764302677029361 22.55376365477147\n",
      "epoch  20 0.91801597582038 13.175483216481709\n",
      "epoch  40 0.9190414507772021 13.031615622097142\n",
      "epoch  60 0.9192033678756477 13.00744115585697\n",
      "epoch  80 0.9195272020725389 13.045530451394118\n",
      "epoch  100 0.9194732297063903 12.925106170881593\n",
      "epoch  120 0.9192303540587219 12.933556770825422\n",
      "epoch  140 0.9196081606217616 12.942249994409723\n",
      "epoch  160 0.9200939119170984 12.878212814709887\n",
      "epoch  180 0.9205526770293609 12.94097222112415\n",
      "epoch  200 0.9203098013816926 12.908043338021258\n",
      "epoch  220 0.9208225388601037 12.86330207477167\n",
      "epoch  240 0.9204177461139896 12.857515074016723\n",
      "epoch  260 0.9208225388601037 12.825803917306688\n",
      "epoch  280 0.9205796632124352 12.82316010438922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[ 11.37254902  36.07843137  58.03921569  81.17647059 100.        ]\n",
      "start training set generation\n",
      "37436\n",
      "9360\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8878424657534246 20.332632652700756\n",
      "epoch  20 0.9220622859589042 12.260190405666005\n",
      "epoch  40 0.9232662671232876 12.08703178085693\n",
      "epoch  60 0.923293022260274 12.035214759715618\n",
      "epoch  80 0.9235338184931506 12.031587441081879\n",
      "epoch  100 0.9228916952054794 12.077636728956273\n",
      "epoch  120 0.9214736729452054 12.034115235282949\n",
      "epoch  140 0.9236408390410958 11.981312477017108\n",
      "epoch  160 0.9232662671232876 12.026019437264091\n",
      "epoch  180 0.9231057363013698 11.998809353946006\n",
      "epoch  200 0.9239886558219178 12.044801262143544\n",
      "10\n",
      "[ 22.35294118  44.31372549  67.05882353  86.2745098  100.        ]\n",
      "start training set generation\n",
      "38352\n",
      "9589\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.7524520033388982 38.49690322366498\n",
      "epoch  20 0.8399154841402338 23.325270433059714\n",
      "epoch  40 0.8408545492487479 23.087651669879595\n",
      "epoch  60 0.8408806343906511 23.050453439180764\n",
      "epoch  80 0.840411101836394 23.028728282909345\n",
      "epoch  100 0.8401763355592654 23.001654849426583\n",
      "epoch  120 0.8416371035058431 22.955506595426883\n",
      "epoch  140 0.8417153589315526 22.952607925427778\n",
      "epoch  160 0.8411936560934892 22.93319419548787\n",
      "epoch  180 0.8414545075125208 22.905306744456087\n",
      "epoch  200 0.8408806343906511 22.930053004040346\n",
      "epoch  220 0.8403328464106845 22.911377032730524\n",
      "epoch  240 0.841324081803005 22.946909777111113\n",
      "epoch  260 0.8407502086811353 22.881393886368745\n",
      "epoch  280 0.8417936143572621 22.893080074520466\n",
      "11\n",
      "[ 22.35294118  45.09803922  67.05882353  82.35294118 100.        ]\n",
      "start training set generation\n",
      "38412\n",
      "9604\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.75625 38.389932222366355\n",
      "epoch  20 0.8405208333333334 23.853205739657096\n",
      "epoch  40 0.8385677083333334 23.582690857251475\n",
      "epoch  60 0.8396875 23.50334715684254\n",
      "epoch  80 0.8413541666666666 23.45753801186879\n",
      "epoch  100 0.8397395833333333 23.457985046704618\n",
      "epoch  120 0.8404166666666667 23.38583367983501\n",
      "epoch  140 0.8397395833333333 23.503415797551487\n",
      "epoch  160 0.8405208333333334 23.383880929946894\n",
      "epoch  180 0.8396614583333334 23.389963798522956\n",
      "epoch  200 0.8403125 23.40632756551104\n",
      "epoch  220 0.8412239583333333 23.391629039446524\n",
      "epoch  240 0.8403385416666667 23.356550602912904\n",
      "epoch  260 0.840859375 23.368557879130037\n",
      "epoch  280 0.840625 23.393987072308867\n",
      "12\n",
      "[ 13.33333333  38.03921569  62.35294118  87.05882353 100.        ]\n",
      "start training set generation\n",
      "38234\n",
      "9559\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8497435092127303 25.80990620394246\n",
      "epoch  20 0.8989216917922948 15.750982521766394\n",
      "epoch  40 0.9004658710217756 15.623438958147263\n",
      "epoch  60 0.8997853852596315 15.586672336412235\n",
      "epoch  80 0.9007537688442211 15.533491827135709\n",
      "epoch  100 0.900963149078727 15.531114343822102\n",
      "epoch  120 0.9003088358458962 15.552530019526898\n",
      "epoch  140 0.9002826633165829 15.539121898574447\n",
      "epoch  160 0.8995760050251256 15.506858379996595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "[ 17.25490196  41.17647059  60.39215686  85.09803922 100.        ]\n",
      "start training set generation\n",
      "39045\n",
      "9762\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.7905481557377049 34.91212914576298\n",
      "epoch  20 0.8639088114754099 20.835308200023206\n",
      "epoch  40 0.8654456967213114 20.70463906272511\n",
      "epoch  60 0.8668801229508196 20.565699603909334\n",
      "epoch  80 0.8653432377049181 20.534271563858287\n",
      "epoch  100 0.865061475409836 20.565107289298656\n",
      "epoch  120 0.8655737704918033 20.523771219566225\n",
      "epoch  140 0.8657530737704918 20.493758176584713\n",
      "epoch  160 0.8663678278688525 20.488640072306648\n",
      "epoch  180 0.8663422131147541 20.498711143556175\n",
      "epoch  200 0.8657786885245902 20.484489300211912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "[ 15.29411765  39.21568627  63.1372549   75.29411765 100.        ]\n",
      "start training set generation\n",
      "38720\n",
      "9681\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8029700413223141 31.896639931103444\n",
      "epoch  20 0.868956611570248 19.61741155514047\n",
      "epoch  40 0.8698863636363636 19.40019873311697\n",
      "epoch  60 0.8701446280991736 19.3083361294644\n",
      "epoch  80 0.8705061983471074 19.279901775643857\n",
      "epoch  100 0.8713584710743801 19.15435119187536\n",
      "epoch  120 0.8708419421487603 19.23502338819268\n",
      "epoch  140 0.8713842975206612 19.179317712389732\n",
      "15\n",
      "[ 11.37254902  35.29411765  59.21568627  81.17647059 100.        ]\n",
      "start training set generation\n",
      "38607\n",
      "9652\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.822217039800995 29.267110196709837\n",
      "epoch  20 0.8820999170812603 17.860861970417552\n",
      "epoch  40 0.8837842039800995 17.624653369435425\n",
      "epoch  60 0.882929104477612 17.530537679618472\n",
      "epoch  80 0.8841469734660033 17.465494582111354\n",
      "epoch  100 0.8837582918739635 17.465573855695812\n",
      "epoch  120 0.8840951492537313 17.41590597222298\n",
      "epoch  140 0.8830068407960199 17.4122474110542\n",
      "epoch  160 0.8839915008291874 17.360926194768236\n",
      "epoch  180 0.8845356550580431 17.372013889932713\n",
      "epoch  200 0.8844060945273632 17.350450582172137\n",
      "epoch  220 0.884691127694859 17.290208169279218\n",
      "epoch  240 0.8846133913764511 17.297457580344968\n",
      "epoch  260 0.8852611940298507 17.298124668412367\n",
      "epoch  280 0.8856498756218906 17.29521914303402\n",
      "epoch  300 0.8851057213930348 17.295800194811473\n",
      "epoch  320 0.8854425787728026 17.28212191532702\n",
      "epoch  340 0.8858571724709784 17.256482282088154\n",
      "epoch  360 0.8862717661691543 17.230671612184437\n",
      "epoch  380 0.8843542703150912 17.3102194230948\n",
      "epoch  400 0.8845615671641791 17.287387950701092\n",
      "16\n",
      "[ 11.37254902  36.07843137  60.39215686  83.1372549  100.        ]\n",
      "start training set generation\n",
      "38490\n",
      "9623\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8393562811980033 26.816457281890205\n",
      "epoch  20 0.8935108153078203 16.274721476480302\n",
      "epoch  40 0.8942127703826955 16.045828414637697\n",
      "epoch  60 0.8957986688851913 15.938070485278496\n",
      "epoch  80 0.8952007071547421 15.896390576925928\n",
      "epoch  100 0.8944207570715474 15.968097706602737\n",
      "epoch  120 0.8963186356073212 15.87578145200123\n",
      "epoch  140 0.8951747088186356 15.944806725728926\n",
      "epoch  160 0.8965006239600666 15.858431119490383\n",
      "epoch  180 0.8963446339434277 15.896667044095311\n",
      "epoch  200 0.8956166805324459 15.898860997249203\n",
      "epoch  220 0.8958766638935108 15.907016760497644\n",
      "17\n",
      "[ 23.1372549   46.2745098   66.2745098   80.39215686 100.        ]\n",
      "start training set generation\n",
      "38067\n",
      "9517\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8126578282828283 30.47707178777317\n",
      "epoch  20 0.8804450757575758 17.93184352643561\n",
      "epoch  40 0.8797874579124579 17.661028084128798\n",
      "epoch  60 0.8793928872053872 17.595115847860516\n",
      "epoch  80 0.8800505050505051 17.59320387695773\n",
      "epoch  100 0.8789194023569024 17.57323006026271\n",
      "epoch  120 0.8787878787878788 17.582638285376802\n",
      "epoch  140 0.8786563552188552 17.56627684972101\n",
      "epoch  160 0.8799189814814815 17.554657716141016\n",
      "epoch  180 0.8787089646464646 17.528415036121196\n",
      "epoch  200 0.8792350589225589 17.536715831820814\n",
      "epoch  220 0.8796559343434344 17.527883981614778\n",
      "18\n",
      "[ 10.19607843  32.15686275  56.07843137  78.03921569 100.        ]\n",
      "start training set generation\n",
      "37120\n",
      "9281\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8553609913793103 24.32754021184197\n",
      "epoch  20 0.9111260775862069 13.896903623383622\n",
      "epoch  40 0.9121497844827586 13.61303616474415\n",
      "epoch  60 0.9120959051724138 13.519818306791374\n",
      "epoch  80 0.9126077586206897 13.439274485768946\n",
      "epoch  100 0.9132004310344828 13.469659841471705\n",
      "epoch  120 0.9127963362068966 13.390310348313433\n",
      "epoch  140 0.9131196120689655 13.375933308436956\n",
      "epoch  160 0.9128771551724137 13.390968427164802\n",
      "epoch  180 0.9133081896551725 13.347951928500475\n",
      "epoch  200 0.9135506465517241 13.384489958861776\n",
      "epoch  220 0.9137392241379311 13.39276478208344\n",
      "epoch  240 0.9131196120689655 13.372475199041698\n",
      "epoch  260 0.9129040948275862 13.36806169542773\n",
      "epoch  280 0.9131196120689655 13.329763444127707\n",
      "epoch  300 0.9138739224137931 13.298416306232593\n",
      "epoch  320 0.9133351293103448 13.333651508956118\n",
      "epoch  340 0.9138200431034482 13.331922927807119\n",
      "epoch  360 0.913415948275862 13.327458412071756\n",
      "epoch  380 0.9142780172413794 13.305872600243005\n",
      "epoch  400 0.9139547413793103 13.363444500544981\n",
      "19\n",
      "[ 15.29411765  39.21568627  63.1372549   87.05882353 100.        ]\n",
      "start training set generation\n",
      "38690\n",
      "9673\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8439310844370861 27.73314902324551\n",
      "epoch  20 0.9039217715231788 15.084340724724019\n",
      "epoch  40 0.9055515314569537 14.897863813583424\n",
      "epoch  60 0.9058102235099338 14.859001386244566\n",
      "epoch  80 0.9052669701986755 14.800352433659386\n",
      "epoch  100 0.9050858857615894 14.815074925391084\n",
      "epoch  120 0.9057584850993378 14.73248543644583\n",
      "epoch  140 0.9060430463576159 14.760870270381696\n",
      "epoch  160 0.9065862996688742 14.813078150843939\n",
      "epoch  180 0.9066639072847682 14.664577319922037\n",
      "epoch  200 0.9071295529801324 14.699112633206196\n",
      "epoch  220 0.9066121688741722 14.651243908515832\n",
      "epoch  240 0.9059395695364238 14.62873164194309\n",
      "epoch  260 0.9059913079470199 14.638172949386751\n",
      "epoch  280 0.906301738410596 14.627402207709306\n",
      "epoch  300 0.9072071605960265 14.6284313849266\n",
      "epoch  320 0.9069225993377483 14.60307474957397\n",
      "epoch  340 0.9067673841059603 14.562663026992846\n",
      "epoch  360 0.9073882450331126 14.567030303525609\n",
      "epoch  380 0.9068449917218543 14.581216546083915\n",
      "20\n",
      "[ 11.37254902  36.07843137  60.39215686  78.03921569 100.        ]\n",
      "start training set generation\n",
      "37980\n",
      "9495\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8751317453625632 21.078074736699705\n",
      "epoch  20 0.9208737352445194 12.435944053013047\n",
      "epoch  40 0.9211372259696459 12.277490278118584\n",
      "epoch  60 0.9215324620573356 12.245972397355564\n",
      "epoch  80 0.9218486509274874 12.251766867822582\n",
      "epoch  100 0.921348018549747 12.234534661243183\n",
      "epoch  120 0.9222965851602024 12.173252080785488\n",
      "epoch  140 0.9227181703204047 12.176474217017631\n",
      "epoch  160 0.9217696037099494 12.19218193740909\n",
      "epoch  180 0.9220594435075885 12.169947770956606\n",
      "epoch  200 0.922243887015177 12.123721740700137\n",
      "epoch  220 0.9226391231028668 12.16563145788685\n",
      "epoch  240 0.9220594435075885 12.148876250895842\n",
      "epoch  260 0.9236930860033726 12.078483916052676\n",
      "epoch  280 0.9226127740303541 12.095151270822974\n",
      "epoch  300 0.9211899241146712 12.177762799480105\n",
      "21\n",
      "[ 20.39215686  45.09803922  64.31372549  88.23529412 100.        ]\n",
      "start training set generation\n",
      "38784\n",
      "9697\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8165738448844885 27.937147389150688\n",
      "epoch  20 0.8835602310231023 16.649312954137827\n",
      "epoch  40 0.884101691419142 16.553461955325446\n",
      "epoch  60 0.8840501237623762 16.465374641292566\n",
      "epoch  80 0.8848494224422442 16.47519681634681\n",
      "epoch  100 0.8850814768976898 16.486236311814967\n",
      "epoch  120 0.8846947194719472 16.388386662643736\n",
      "epoch  140 0.8854940181518152 16.372638108313268\n",
      "epoch  160 0.8850814768976898 16.398401929993863\n",
      "epoch  180 0.883766501650165 16.471319407913153\n",
      "epoch  200 0.8860354785478548 16.40700717491677\n",
      "22\n",
      "[ 11.37254902  36.07843137  55.29411765  76.07843137 100.        ]\n",
      "start training set generation\n",
      "38029\n",
      "9508\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.8895991161616161 19.15689489576553\n",
      "epoch  20 0.9296348905723906 11.461066975336692\n",
      "epoch  40 0.9300820707070707 11.297414717449485\n",
      "epoch  60 0.9302135942760943 11.271253106168635\n",
      "epoch  80 0.9308712121212122 11.208507406591167\n",
      "epoch  100 0.928950968013468 11.176585216313503\n",
      "epoch  120 0.9292403198653199 11.185752051045196\n",
      "epoch  140 0.9296348905723906 11.114247448115243\n",
      "epoch  160 0.9304503367003367 11.122234612201606\n",
      "epoch  180 0.9300820707070707 11.119565713285203\n",
      "epoch  200 0.9296085858585859 11.062234673034457\n",
      "epoch  220 0.9297138047138047 11.090253129952682\n",
      "epoch  240 0.9302135942760943 11.088107410304064\n",
      "epoch  260 0.9309238215488216 11.044404700548961\n",
      "epoch  280 0.9299768518518519 11.033959079270419\n",
      "epoch  300 0.9305292508417509 11.013609641730183\n",
      "epoch  320 0.9302662037037037 11.01126325893081\n",
      "epoch  340 0.9288457491582491 11.084558783958261\n",
      "epoch  360 0.9303714225589226 11.06802423674651\n",
      "epoch  380 0.9306870791245792 11.004598149145492\n",
      "epoch  400 0.9300820707070707 11.01336996643632\n",
      "epoch  420 0.9295296717171717 11.006038936300307\n",
      "epoch  440 0.9298453282828283 10.99916137589348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "[ 13.33333333  38.03921569  62.35294118  82.35294118 100.        ]\n",
      "start training set generation\n",
      "38016\n",
      "9504\n",
      "starting tensor\n",
      "Initialized\n",
      "epoch  0 0.876288930976431 22.383229945243798\n",
      "epoch  20 0.921690867003367 12.695792072951193\n",
      "epoch  40 0.9222958754208754 12.554959327684921\n",
      "epoch  60 0.9226641414141414 12.482668871831407\n",
      "epoch  80 0.923348063973064 12.396856786827453\n",
      "epoch  100 0.9219013047138047 12.386456703497506\n",
      "epoch  120 0.9223747895622896 12.378349274898614\n",
      "epoch  140 0.9227693602693603 12.30333879901102\n",
      "epoch  160 0.9224800084175084 12.270334750313545\n",
      "epoch  180 0.9224010942760943 12.255172267506019\n",
      "epoch  200 0.923348063973064 12.258665569703595\n",
      "epoch  220 0.9234269781144782 12.24159540592219\n",
      "epoch  240 0.9234006734006734 12.20263092967396\n",
      "epoch  260 0.922611531986532 12.213782915763979\n",
      "epoch  280 0.9225589225589226 12.148810225705104\n",
      "epoch  300 0.9221906565656566 12.172925129482644\n",
      "epoch  320 0.9237952441077442 12.178166473754738\n",
      "epoch  340 0.9235585016835017 12.127821368400497\n",
      "epoch  360 0.922795664983165 12.145083778635025\n",
      "epoch  380 0.9235585016835017 12.140059223881485\n",
      "epoch  400 0.9225589225589226 12.141546198013252\n",
      "epoch  420 0.9234269781144782 12.130319991095694\n",
      "epoch  440 0.9228745791245792 12.160085386700104\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "for timeIndex in range(len(normalLumping)):\n",
    "    if len(normalLumping[timeIndex]) == 0:\n",
    "        continue\n",
    "    \n",
    "    print(timeIndex)\n",
    "    boundaries = np.array([])\n",
    "    for i in range(1, len(normalLumping[0][0][3])):\n",
    "        bound = normalLumping[timeIndex][0][3][i] + 1\n",
    "        counter = 0\n",
    "        for j in range(len(percentageArray[timeIndex])):\n",
    "            if percentageArray[timeIndex][j][2] == False:\n",
    "                counter += 1\n",
    "            if counter == bound:\n",
    "                boundaries = np.append(boundaries, percentageArray[timeIndex][j][1])\n",
    "                break\n",
    "    boundaries = np.append(boundaries,100)\n",
    "    print(boundaries)\n",
    "    \n",
    "    XArraysForLearning, YArraysForLearning, XArraysForTesting, YArraysForTesting, boundaries = dataPreparation(\n",
    "        data, timeIndex, 30, boundaries)\n",
    "\n",
    "    print(\"starting tensor\")\n",
    "    lossFunctionBoolean = 0\n",
    "    accuracy_result, penaltyValue, precision, recall, f1Score = tensorFlowLossFunction(\n",
    "        lossFunctionBoolean, XArraysForLearning, YArraysForLearning, XArraysForTesting, \n",
    "        YArraysForTesting, boundaries)\n",
    "    \n",
    "    result_25_10_5class_60min_DataFrameNoPenalty.loc[timeIndex][\"accuracy\"] = accuracy_result\n",
    "    result_25_10_5class_60min_DataFrameNoPenalty.loc[timeIndex][\"penalty\"] = penaltyValue\n",
    "    result_25_10_5class_60min_DataFrameNoPenalty.loc[timeIndex][\"precision\"] = precision\n",
    "    result_25_10_5class_60min_DataFrameNoPenalty.loc[timeIndex][\"recall\"] = recall\n",
    "    result_25_10_5class_60min_DataFrameNoPenalty.loc[timeIndex][\"f1Score\"] = f1Score\n",
    "    result_25_10_5class_60min_DataFrameNoPenalty.loc[timeIndex][\"boundaries\"] = boundaries\n",
    "    result_25_10_5class_60min_DataFrameNoPenalty.loc[timeIndex][\"lumpAprox\"] = normalLumping[timeIndex][0][0]\n",
    "    result_25_10_5class_60min_DataFrameNoPenalty.loc[timeIndex][\"lumpError\"] = normalLumping[timeIndex][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>penalty</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1Score</th>\n",
       "      <th>boundaries</th>\n",
       "      <th>lumpAprox</th>\n",
       "      <th>lumpError</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.936887</td>\n",
       "      <td>24.2353</td>\n",
       "      <td>0.935767</td>\n",
       "      <td>0.936887</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>[10.196078431372554, 32.156862745097996, 51.37...</td>\n",
       "      <td>1</td>\n",
       "      <td>50.3981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.936197</td>\n",
       "      <td>30.0824</td>\n",
       "      <td>0.934878</td>\n",
       "      <td>0.936197</td>\n",
       "      <td>0.934589</td>\n",
       "      <td>[10.196078431372554, 34.11764705882348, 51.372...</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.961958</td>\n",
       "      <td>15.793</td>\n",
       "      <td>0.961073</td>\n",
       "      <td>0.961958</td>\n",
       "      <td>0.961514</td>\n",
       "      <td>[24.31372549019606, 42.35294117647051, 54.1176...</td>\n",
       "      <td>1</td>\n",
       "      <td>31.2278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.961017</td>\n",
       "      <td>25.0228</td>\n",
       "      <td>0.959007</td>\n",
       "      <td>0.961017</td>\n",
       "      <td>0.959699</td>\n",
       "      <td>[23.13725490196077, 45.098039215686185, 58.039...</td>\n",
       "      <td>1</td>\n",
       "      <td>24.5647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.964117</td>\n",
       "      <td>26.3532</td>\n",
       "      <td>0.963371</td>\n",
       "      <td>0.964117</td>\n",
       "      <td>0.963685</td>\n",
       "      <td>[24.31372549019606, 49.01960784313715, 61.1764...</td>\n",
       "      <td>1</td>\n",
       "      <td>29.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.958418</td>\n",
       "      <td>29.4082</td>\n",
       "      <td>0.957827</td>\n",
       "      <td>0.958418</td>\n",
       "      <td>0.958121</td>\n",
       "      <td>[24.31372549019606, 49.01960784313715, 70.1960...</td>\n",
       "      <td>1</td>\n",
       "      <td>27.4457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.944053</td>\n",
       "      <td>10.7142</td>\n",
       "      <td>0.947422</td>\n",
       "      <td>0.944053</td>\n",
       "      <td>0.945462</td>\n",
       "      <td>[24.31372549019606, 35.29411764705877, 51.3725...</td>\n",
       "      <td>1</td>\n",
       "      <td>30.5962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.918192</td>\n",
       "      <td>39.9345</td>\n",
       "      <td>0.917451</td>\n",
       "      <td>0.918192</td>\n",
       "      <td>0.916823</td>\n",
       "      <td>[11.372549019607849, 36.07843137254896, 55.294...</td>\n",
       "      <td>1</td>\n",
       "      <td>41.7783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.922165</td>\n",
       "      <td>44.8494</td>\n",
       "      <td>0.92022</td>\n",
       "      <td>0.922165</td>\n",
       "      <td>0.920805</td>\n",
       "      <td>[13.333333333333341, 37.25490196078425, 60.392...</td>\n",
       "      <td>1</td>\n",
       "      <td>40.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.911752</td>\n",
       "      <td>50.049</td>\n",
       "      <td>0.917868</td>\n",
       "      <td>0.911752</td>\n",
       "      <td>0.913926</td>\n",
       "      <td>[11.372549019607849, 36.07843137254896, 58.039...</td>\n",
       "      <td>1</td>\n",
       "      <td>46.1633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.836166</td>\n",
       "      <td>79.9872</td>\n",
       "      <td>0.840679</td>\n",
       "      <td>0.836166</td>\n",
       "      <td>0.835175</td>\n",
       "      <td>[22.352941176470576, 44.31372549019599, 67.058...</td>\n",
       "      <td>0.513672</td>\n",
       "      <td>40.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.835798</td>\n",
       "      <td>80.0294</td>\n",
       "      <td>0.839789</td>\n",
       "      <td>0.835798</td>\n",
       "      <td>0.832792</td>\n",
       "      <td>[22.352941176470576, 45.098039215686185, 67.05...</td>\n",
       "      <td>0.571289</td>\n",
       "      <td>39.3208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.898316</td>\n",
       "      <td>70.7365</td>\n",
       "      <td>0.895584</td>\n",
       "      <td>0.898316</td>\n",
       "      <td>0.896502</td>\n",
       "      <td>[13.333333333333341, 38.039215686274446, 62.35...</td>\n",
       "      <td>1</td>\n",
       "      <td>44.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.853001</td>\n",
       "      <td>69.3129</td>\n",
       "      <td>0.851143</td>\n",
       "      <td>0.853001</td>\n",
       "      <td>0.846074</td>\n",
       "      <td>[17.25490196078432, 41.17647058823522, 60.3921...</td>\n",
       "      <td>0.821777</td>\n",
       "      <td>42.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.878008</td>\n",
       "      <td>73.9707</td>\n",
       "      <td>0.875724</td>\n",
       "      <td>0.878008</td>\n",
       "      <td>0.875557</td>\n",
       "      <td>[15.294117647058833, 39.215686274509736, 63.13...</td>\n",
       "      <td>0.86377</td>\n",
       "      <td>38.8447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.884169</td>\n",
       "      <td>68.128</td>\n",
       "      <td>0.881166</td>\n",
       "      <td>0.884169</td>\n",
       "      <td>0.875566</td>\n",
       "      <td>[11.372549019607849, 35.29411764705877, 59.215...</td>\n",
       "      <td>0.777832</td>\n",
       "      <td>43.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.894524</td>\n",
       "      <td>68.0785</td>\n",
       "      <td>0.890195</td>\n",
       "      <td>0.894524</td>\n",
       "      <td>0.886855</td>\n",
       "      <td>[11.372549019607849, 36.07843137254896, 60.392...</td>\n",
       "      <td>0.692383</td>\n",
       "      <td>35.7626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.869917</td>\n",
       "      <td>57.7082</td>\n",
       "      <td>0.881468</td>\n",
       "      <td>0.869917</td>\n",
       "      <td>0.871773</td>\n",
       "      <td>[23.13725490196077, 46.274509803921475, 66.274...</td>\n",
       "      <td>0.722168</td>\n",
       "      <td>42.9648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.915095</td>\n",
       "      <td>47.2108</td>\n",
       "      <td>0.913335</td>\n",
       "      <td>0.915095</td>\n",
       "      <td>0.913377</td>\n",
       "      <td>[10.196078431372554, 32.156862745097996, 56.07...</td>\n",
       "      <td>1</td>\n",
       "      <td>44.8955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.906958</td>\n",
       "      <td>62.7996</td>\n",
       "      <td>0.906428</td>\n",
       "      <td>0.906958</td>\n",
       "      <td>0.906537</td>\n",
       "      <td>[15.294117647058833, 39.215686274509736, 63.13...</td>\n",
       "      <td>0.666992</td>\n",
       "      <td>39.5437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.922486</td>\n",
       "      <td>48.9592</td>\n",
       "      <td>0.919174</td>\n",
       "      <td>0.922486</td>\n",
       "      <td>0.920198</td>\n",
       "      <td>[11.372549019607849, 36.07843137254896, 60.392...</td>\n",
       "      <td>1</td>\n",
       "      <td>43.9199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.878622</td>\n",
       "      <td>67.7232</td>\n",
       "      <td>0.887244</td>\n",
       "      <td>0.878622</td>\n",
       "      <td>0.881197</td>\n",
       "      <td>[20.392156862745093, 45.098039215686185, 64.31...</td>\n",
       "      <td>1</td>\n",
       "      <td>42.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.931637</td>\n",
       "      <td>42.4584</td>\n",
       "      <td>0.929983</td>\n",
       "      <td>0.931637</td>\n",
       "      <td>0.930476</td>\n",
       "      <td>[11.372549019607849, 36.07843137254896, 55.294...</td>\n",
       "      <td>0.666992</td>\n",
       "      <td>29.6572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.924979</td>\n",
       "      <td>53.9841</td>\n",
       "      <td>0.925565</td>\n",
       "      <td>0.924979</td>\n",
       "      <td>0.925227</td>\n",
       "      <td>[13.333333333333341, 38.039215686274446, 62.35...</td>\n",
       "      <td>1</td>\n",
       "      <td>39.4004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  penalty precision    recall   f1Score  \\\n",
       "0   0.936887  24.2353  0.935767  0.936887  0.934066   \n",
       "1   0.936197  30.0824  0.934878  0.936197  0.934589   \n",
       "2   0.961958   15.793  0.961073  0.961958  0.961514   \n",
       "3   0.961017  25.0228  0.959007  0.961017  0.959699   \n",
       "4   0.964117  26.3532  0.963371  0.964117  0.963685   \n",
       "5   0.958418  29.4082  0.957827  0.958418  0.958121   \n",
       "6   0.944053  10.7142  0.947422  0.944053  0.945462   \n",
       "7   0.918192  39.9345  0.917451  0.918192  0.916823   \n",
       "8   0.922165  44.8494   0.92022  0.922165  0.920805   \n",
       "9   0.911752   50.049  0.917868  0.911752  0.913926   \n",
       "10  0.836166  79.9872  0.840679  0.836166  0.835175   \n",
       "11  0.835798  80.0294  0.839789  0.835798  0.832792   \n",
       "12  0.898316  70.7365  0.895584  0.898316  0.896502   \n",
       "13  0.853001  69.3129  0.851143  0.853001  0.846074   \n",
       "14  0.878008  73.9707  0.875724  0.878008  0.875557   \n",
       "15  0.884169   68.128  0.881166  0.884169  0.875566   \n",
       "16  0.894524  68.0785  0.890195  0.894524  0.886855   \n",
       "17  0.869917  57.7082  0.881468  0.869917  0.871773   \n",
       "18  0.915095  47.2108  0.913335  0.915095  0.913377   \n",
       "19  0.906958  62.7996  0.906428  0.906958  0.906537   \n",
       "20  0.922486  48.9592  0.919174  0.922486  0.920198   \n",
       "21  0.878622  67.7232  0.887244  0.878622  0.881197   \n",
       "22  0.931637  42.4584  0.929983  0.931637  0.930476   \n",
       "23  0.924979  53.9841  0.925565  0.924979  0.925227   \n",
       "\n",
       "                                           boundaries lumpAprox lumpError  \n",
       "0   [10.196078431372554, 32.156862745097996, 51.37...         1   50.3981  \n",
       "1   [10.196078431372554, 34.11764705882348, 51.372...         1   25.0013  \n",
       "2   [24.31372549019606, 42.35294117647051, 54.1176...         1   31.2278  \n",
       "3   [23.13725490196077, 45.098039215686185, 58.039...         1   24.5647  \n",
       "4   [24.31372549019606, 49.01960784313715, 61.1764...         1    29.838  \n",
       "5   [24.31372549019606, 49.01960784313715, 70.1960...         1   27.4457  \n",
       "6   [24.31372549019606, 35.29411764705877, 51.3725...         1   30.5962  \n",
       "7   [11.372549019607849, 36.07843137254896, 55.294...         1   41.7783  \n",
       "8   [13.333333333333341, 37.25490196078425, 60.392...         1    40.969  \n",
       "9   [11.372549019607849, 36.07843137254896, 58.039...         1   46.1633  \n",
       "10  [22.352941176470576, 44.31372549019599, 67.058...  0.513672    40.009  \n",
       "11  [22.352941176470576, 45.098039215686185, 67.05...  0.571289   39.3208  \n",
       "12  [13.333333333333341, 38.039215686274446, 62.35...         1    44.751  \n",
       "13  [17.25490196078432, 41.17647058823522, 60.3921...  0.821777     42.04  \n",
       "14  [15.294117647058833, 39.215686274509736, 63.13...   0.86377   38.8447  \n",
       "15  [11.372549019607849, 35.29411764705877, 59.215...  0.777832    43.791  \n",
       "16  [11.372549019607849, 36.07843137254896, 60.392...  0.692383   35.7626  \n",
       "17  [23.13725490196077, 46.274509803921475, 66.274...  0.722168   42.9648  \n",
       "18  [10.196078431372554, 32.156862745097996, 56.07...         1   44.8955  \n",
       "19  [15.294117647058833, 39.215686274509736, 63.13...  0.666992   39.5437  \n",
       "20  [11.372549019607849, 36.07843137254896, 60.392...         1   43.9199  \n",
       "21  [20.392156862745093, 45.098039215686185, 64.31...         1    42.325  \n",
       "22  [11.372549019607849, 36.07843137254896, 55.294...  0.666992   29.6572  \n",
       "23  [13.333333333333341, 38.039215686274446, 62.35...         1   39.4004  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_25_10_5class_60min_DataFrameNoPenalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"/home/sepehr/thesis/APDataML/result_25_10_6class_10min_DataFrameNoPenalty.pickle\"\n",
    "with open(name, 'rb') as handle:\n",
    "    plt10 = pickle.load(handle)\n",
    "\n",
    "name = \"/home/sepehr/thesis/APDataML/result_25_10_6class_DataFrameNoPenalty.pickle\"\n",
    "with open(name, 'rb') as handle:\n",
    "    plt20 = pickle.load(handle) \n",
    "    \n",
    "name = \"/home/sepehr/thesis/APDataML/6class_LR_noPenalty_normal.pickle\"\n",
    "with open(name, 'rb') as handle:\n",
    "    plt30 = pickle.load(handle)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt60 = result_25_10_6class_60min_DataFrameNoPenalty[\"accuracy\"].tolist()\n",
    "plt60_min_to_10 = []\n",
    "for i in range(len(plt60)):\n",
    "    if plt60[i] == np.inf:\n",
    "        plt60[i] = plt60[i - 1]\n",
    "    for j in range(6):\n",
    "        plt60_min_to_10.append(plt60[i])\n",
    "\n",
    "plt30 = plt30[\"accuracy\"].tolist()\n",
    "plt30_min_to_10 = []\n",
    "for i in range(len(plt30)):\n",
    "    if plt30[i] == np.inf:\n",
    "        plt30[i] = plt30[i - 1]\n",
    "    for j in range(3):\n",
    "        plt30_min_to_10.append(plt30[i])\n",
    "        \n",
    "plt20 = plt20[\"accuracy\"].tolist()\n",
    "plt20_min_to_10 = []\n",
    "for i in range(len(plt20)):\n",
    "    if plt20[i] == np.inf:\n",
    "        plt20[i] = plt20[i - 1]\n",
    "    for j in range(2):\n",
    "        plt20_min_to_10.append(plt20[i])\n",
    "        \n",
    "plt10 = plt10[\"accuracy\"].tolist()\n",
    "plt10_min_to_10 = []\n",
    "for i in range(len(plt10)):\n",
    "    if plt10[i] == np.inf:\n",
    "        plt10[i] = plt10[i - 1]\n",
    "    for j in range(1):\n",
    "        plt10_min_to_10.append(plt10[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9089378074601958\n",
      "0.912194407601012\n",
      "0.9090787877551239\n",
      "0.909703702648971\n"
     ]
    }
   ],
   "source": [
    "plt20_min_to_10.append(plt20_min_to_10[-1])\n",
    "plt20_min_to_10.append(plt20_min_to_10[-1])\n",
    "print(np.mean(plt60_min_to_10))\n",
    "print(np.mean(plt30_min_to_10))\n",
    "print(np.mean(plt20_min_to_10))\n",
    "print(np.mean(plt10_min_to_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('time-interval')\n",
    "plt.ylabel('accuracy')\n",
    "time = [i for i in range(144)]\n",
    "plt.ylim(0.5, 1)\n",
    "plt.plot(time, plt10_min_to_10, \"b\", label=\"\\u03C4 = 10\")\n",
    "plt.plot(time, plt20_min_to_10, \"r\", label=\"\\u03C4 = 20\")\n",
    "plt.plot(time, plt30_min_to_10, \"g\", label=\"\\u03C4 = 30\")\n",
    "plt.plot(time, plt60_min_to_10, \"black\", label=\"\\u03C4 = 60\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"different_tau_values.svg\", format=\"svg\")\n",
    "plt.savefig(\"different_tau_values.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
